{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Regional Land Cover Monitoring System","text":""},{"location":"#installation","title":"Installation","text":"<p>Install with pip: </p> <pre><code>pip install rlcms\n</code></pre> <p>Test that <code>earthengine-api</code> is setup and authenticated by checking the folder contents within one of your cloud projects.  * In your shell, run:</p> <pre><code>earthengine set_project &lt;project-name&gt;\nearthengine ls projects/project-name/assets\n</code></pre> <p>If you do not get an error and it returns a list of folders and assets similar to this then you are good to go! :tada:</p>"},{"location":"#features","title":"Features","text":"<ul> <li>stratified sampling for use in Collect Earth Online</li> <li>Training and validation data extraction, from points or polygon references</li> <li>Land cover modeling using Primitive ensembles, complete with model metrics for iterative improvements</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from rlcms.composites import Composite\n# Create an annual Sentinel-1 Composite\nc = Composite(dataset='Sentinel1',\n        region=aoi,\n        start_date='2020-01-01',\n        end_date='2021-12-31',\n        composite_mode='annual',\n        reducer='median')\n\n# look at the Composite object\nprint(c.__dict__)\n\n# retrieve band names\nprint(f\"Composite bands:{c.bands}\")\n\n# retrieve ee.Image from Composite object \nimage = c.image\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions from the community. If there are issues are improvements, please submit an issue on Github: https://github.com/sig-gis/rlcms</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the GPL-3 License - see the LICENSE file for details.</p>"},{"location":"about/","title":"About RLCMS","text":"<p>Monitoring land cover and land use change by providing accurate and timely land cover maps and information, plays a critical role in multiple sectors in the developing world including agricultural planning and food security, carbon accounting, water management and natural resource management. However, many developing countries, including those within the Lower Mekong region, lack the coordinated capacity to produce timely, and temporally comparable geospatial data products sufficient to meet their management needs.</p> <p>The Regional Land Cover Monitoring System (RLCMS) was developed by SERVIR-Mekong with the support of the U.S. Forest Service, NASA Applied Science Program, Google, the University of Maryland and governments of countries in the Mekong region. The system utilizes satellite technology to facilitate the production of customized, high-quality regional land cover maps at a 30-m resolution for each year from 2000 to present, in addition to complimentary land cover information. Using publicly available global satellite data, such as Landsat and MODIS, makes the system easily transferable. The adaptable system framework allows for a customized service that is able to map different land cover typologies based on ongoing user needs and bespoke landscape monitoring objectives.</p> <p></p>"},{"location":"about/#a-python-package-for-co-development","title":"A python package for co-development","text":"<p>The <code>rlcms</code> python package is meant to jump-start local mapping projects and provide a living co-development tool for regional and global collaborators to build methodologies and share reproducible results. </p>"},{"location":"cli/","title":"CLI Tool Documentation","text":"<p>Each Command Line Interface (CLI) script tool can be run in your command-line terminal of choice. The user must provide values for each required command-line argument to control the analysis. You can first run any script, only declaring the <code>-h</code> flag. This will bring up the help dialog with a usage example and a description of required command-line arguments. </p>"},{"location":"cli/#sample_pts","title":"sample_pts","text":"<p>Generate Random Sample Points From an ee.Image, Formatted for Collect Earth Online</p> <p>The points are pre-formatted for use in Collect Earth Online. You can choose to export the points to Google Drive, to GEE Asset or both. </p> <p>example:</p> <pre><code>sample_pts -im input/path/to/image -band LANDCOVER -o output/path --n_points 100 --to_drive\n</code></pre>"},{"location":"cli/#composite","title":"composite","text":"<p>Create a Composite from one or multiple datasets. </p> <p>The resulting band stack is needed for both extracting training data (using <code>train_test</code>) and as input stack for the primitive model training &amp; inference (using <code>primitives</code> tool). </p> <p>There are many compositing options available, which you control in the CLI with your own settings .txt file. Follow this template <code>composite_template_settings.txt</code> to create your own file, then pass this file's path to <code>--settings</code>. </p> <p>If your AOI is a set of reference polygons and not one contiguous AOI polygon, set <code>multi_poly</code> to <code>true</code> in your <code>--settings</code> file - this will export band information only within each polygon's footprint. </p> <p>example:</p> <pre><code>composite -a aoi/fc/path -d Landsat8 -s 2020-01-01 -e 2020-12-31 -o output/path --settings path/to/settings/file.txt\n</code></pre>"},{"location":"cli/#train_test","title":"train_test","text":"<p>Extract Train and Test Point Data from an Input Image using a Reference Locations (can be Point or Polygon).</p> <p>Generates stratified random samples from reference locations, splitting the sample points into train and test points if desired. The image bands from the provided image are extracted to every point. </p> <p>example:</p> <pre><code>train_test -ref path/to/reference_fc -im path/to/input/stack -band LANDCOVER --scale 10\n                -o unique/output/path --class_values 1 2 3 4 5 6 7 8 --class_points 10 10 10 10 10 10 10\n</code></pre>"},{"location":"cli/#primitives","title":"primitives","text":"<p>Create Primitives For All Classes in Provided Training Data. </p> <p>This script trains probability models for each land cover class in your typology as provided by the numeric <code>--class_name</code> property in the provided reference data. It then exports these binary probability images one land cover at a time into a land cover 'Primitives' image collection. Model metrics are retained in the Images themselves as properties, which the user can choose to export to local files by setting a <code>--metrics_folder</code> local folder path during the run. </p> <p>example:</p> <pre><code>primitives -i path/to/input_stack -t path/to/training_data --class_name LANDCOVER -o path/to/output --metrics_folder local/folder/path\n</code></pre>"},{"location":"cli/#landcover","title":"landcover","text":"<p>Generate Single Land Cover Image From Land Cover Primitives Image Collection</p> <p>This script takes a Primitives Image Collection and assembles a single-band land cover image from them using per-pixel max probability.</p> <p>example:</p> <pre><code>landcover -i input/primitives/imagecollection/path -o output/path\n</code></pre>"},{"location":"composites/","title":"composites module","text":""},{"location":"composites/#rlcms.composites.Composite","title":"<code>Composite</code>","text":"<p>Initializes Composite class</p> <p>Processes multi-band composite of your chosen dataset(s) within an AOI footprint polygon</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>one of: 'Landsat5','Landsat7','Landsat8','Sentinel1Asc','Sentinel1Desc','Sentinel2','Modis','Viirs')</p> required <code>region</code> <code>FeatureCollection</code> <p>area of interest</p> required <code>start_date</code> <code>str</code> <p>start date</p> required <code>end_date</code> <code>str</code> <p>end date</p> required kwargs <p>indices:list[str] composite_mode:str One of ['seasonal','annual'] Default = 'annual'  season:list[str|int] reducer:str|ee.Reducer addTasselCap:bool addTopography:bool addJRC:bool harmonicsOptions:dict in this format: {'nir':{'start':int[1:365],'end':[1:365]}}</p> <p>Returns:</p> Type Description <p>ee.Image: multi-band image composite within region</p> Source code in <code>src\\rlcms\\composites.py</code> <pre><code>class Composite:\n    \"\"\"Initializes Composite class\n\n        Processes multi-band composite of your chosen dataset(s) within an AOI footprint polygon\n\n        args:\n            dataset (str): one of: 'Landsat5','Landsat7','Landsat8','Sentinel1Asc','Sentinel1Desc','Sentinel2','Modis','Viirs')\n            region (ee.FeatureCollection): area of interest\n            start_date (str): start date\n            end_date (str): end date\n\n        kwargs:\n            indices:list[str]\n            composite_mode:str One of ['seasonal','annual'] Default = 'annual' \n            season:list[str|int]\n            reducer:str|ee.Reducer\n            addTasselCap:bool\n            addTopography:bool\n            addJRC:bool\n            harmonicsOptions:dict in this format: {'nir':{'start':int[1:365],'end':[1:365]}}\n\n        returns:\n            ee.Image: multi-band image composite within region\n        \"\"\"\n\n    def __init__(self,dataset:str,\n                    region:ee.FeatureCollection,\n                    start_date:str,\n                    end_date:str,\n                    **kwargs):\n\n        self.dataset=dataset\n        if isinstance(region, ee.Geometry):\n            self.region=region.getInfo()['coordinates']\n        elif isinstance(region, ee.FeatureCollection):\n            self.region = region.geometry().getInfo()['coordinates']\n        self.start_date=start_date\n        self.end_date=end_date\n\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\n        # testing whether need to go b/w FC and Geometry for multi_poly\n        if isinstance(region,ee.FeatureCollection):\n            region = region.geometry()\n            region_fc = region\n        elif isinstance(region,ee.Geometry):\n            region = region\n        else:\n            raise TypeError(f\"{region} must be of type ee.FeatureCollection or ee.Geometry, got {type(region)}\")\n        # all hydrafloods.Dataset sub-classes\n        ds_dict = {'Landsat5':hf.Landsat5(region,start_date,end_date),\n                'Landsat7':hf.Landsat7(region,start_date,end_date),\n                'Landsat8':hf.Landsat8(region,start_date,end_date),\n                'Landsat9':hf.Landsat9(region,start_date,end_date),\n                'Sentinel1':hf.Sentinel1(region,start_date,end_date),\n                'Sentinel1Asc':hf.Sentinel1Asc(region,start_date,end_date),\n                'Sentinel1Desc':hf.Sentinel1Desc(region,start_date,end_date),\n                'Sentinel2':hf.Sentinel2(region,start_date,end_date),\n                'MODIS':hf.Modis(region,start_date,end_date),\n                'VIIRS':hf.Viirs(region,start_date,end_date)}\n\n        # dataset can either be a named dataset string supported by a hf.Dataset sub-class \n        # or a GEE Asset path\n        if isinstance(dataset,str):\n            if dataset in ds_dict.keys(): \n                ds = ds_dict[dataset]\n            else:\n                if '/' in dataset: \n                    try:\n                        ds = hf.Dataset(asset_id=dataset,region=region,start_time=start_date,end_time=end_date)\n                    except:\n                        raise EEException\n                else: \n                    raise ValueError(f\"Could not construct a hf.Dataset from dataset name provided: {dataset}\")\n        else:\n            raise TypeError(f\"dataset must be str type, got: {type(dataset)}\")\n\n        # mask imgs to geometries in multi_poly mode\n        if 'multi_poly' in kwargs:\n            if kwargs['multi_poly'] == True:\n                def update_mask(img):\n                    ref_poly_img = ee.Image(1).paint(region_fc).Not().selfMask() # aoi can be ee.Geometry or ee.FeatureCollection for this\n                    return ee.Image(img).updateMask(ref_poly_img)\n                # do we want to warn user against using multi_poly unnecessarily if aoi is a single geometry?\n                # would require another synchronous request of aoi's type/element size\n                ds = ds.apply_func(update_mask)\n\n        ds = ds.apply_func(returnCovariatesFromOptions,**kwargs)\n\n        # set reducer passed to aggregate_time(), default mean\n        if 'reducer' in kwargs:\n            reducer=kwargs['reducer']\n        else:\n            reducer = 'mean'\n\n        period,period_unit,dates = get_agg_timing(ds,**kwargs)\n\n        # aggregate hf.Dataset\n        agg_time_result = (ds.aggregate_time(reducer=reducer,\n                                        rename=False,\n                                        period_unit=period_unit,\n                                        period=period,\n                                        dates=dates)\n                                        )\n\n        composite = ee.ImageCollection(agg_time_result.collection).toBands()\n\n        # rename bands depending on number of resulting images\n        if agg_time_result.n_images &gt; 1:\n            bnames = composite.bandNames().map(lambda b: ee.String('t').cat(b))\n        else:\n            bnames = composite.bandNames().map(lambda b: ee.String(b).slice(2))\n\n        composite = composite.rename(bnames)\n\n        # compute harmonics if desired\n        if 'harmonicsOptions' in kwargs:\n            harmonics_features = doHarmonicsFromOptions(ds.collection,**kwargs) # returns an ee.Image, not a hf.Dataset\n            composite = composite.addBands(harmonics_features)\n\n        # add JRC variables if desired\n        if 'addJRCWater' in kwargs:\n            if kwargs['addJRCWater']:\n                composite = idx.addJRC(composite).unmask(0)\n\n        # add topography variables if desired     \n        if 'addTopography' in kwargs:\n            if kwargs['addTopography']:\n                composite = idx.addTopography(composite).unmask(0)\n\n        self.bands = composite.bandNames().getInfo()\n        self.image = (composite.clip(region).set('dataset',dataset,\n                                                     'start',start_date,\n                                                     'end',end_date)\n                                                    .set(kwargs)\n                                                    )\n        return\n</code></pre>"},{"location":"composites/#rlcms.composites.get_agg_timing","title":"<code>get_agg_timing(collection, **kwargs)</code>","text":"<p>utility function for hf.Dataset.aggregate_time(). Formats <code>period</code>, <code>period_unit</code>, and <code>dates</code> args     to create certain types of composites (defined by <code>composite_mode</code>) args:     collection (hf.Dataset): Hydrafloods Dataset kwargs:     composite_mode (str): one of 'annual' or 'seasonal', Default = 'annual'     season (list[str|int]): consecutive list of months (e.g. ['01','02','03']) comprising the season.         A required arg if composite_mode == 'seasonal' Returns:     tuple(period(int),period_unit(str),dates(list[str]))</p> Source code in <code>src\\rlcms\\composites.py</code> <pre><code>def get_agg_timing(collection:hf.Dataset,**kwargs):\n    \"\"\"utility function for hf.Dataset.aggregate_time(). Formats `period`, `period_unit`, and `dates` args\n        to create certain types of composites (defined by `composite_mode`)\n    args:\n        collection (hf.Dataset): Hydrafloods Dataset\n    kwargs:\n        composite_mode (str): one of 'annual' or 'seasonal', Default = 'annual'\n        season (list[str|int]): consecutive list of months (e.g. ['01','02','03']) comprising the season.\n            A required arg if composite_mode == 'seasonal'\n    Returns:\n        tuple(period(int),period_unit(str),dates(list[str]))\n\n    \"\"\"\n    if 'composite_mode' not in kwargs:\n        composite_mode = 'annual'\n    else:\n        composite_mode = kwargs['composite_mode']\n\n    # get unique yyyy strings\n    years = list(set([d.split(' ')[0].split('-')[0] for d in collection.dates])) \n    years.sort()\n\n    if composite_mode == 'seasonal':\n        if 'season' not in kwargs:\n            raise ValueError(\"season arg required if composite_mode == 'seasonal'\")\n        else:\n            season = kwargs['season'] # must be consecutive \n            period = len(season)\n            period_unit = 'month'\n            dates = [f\"{y}-{str(season[0])}-01\" for y in years]\n    elif composite_mode == 'annual':\n        period = 1\n        period_unit = 'year'\n        dates = [y+'-01-01' for y in years]\n\n    else:\n        raise ValueError(f\"{composite_mode} not a valid 'composite_mode'. Choose one of 'annual' or 'seasonal'\")\n\n    return period,period_unit,dates\n</code></pre>"},{"location":"composites/#rlcms.composites.stack","title":"<code>stack(composites)</code>","text":"<p>stacks a list of rlcms.Composites together, prefixing each band with the Composite's dataset name args:     composites: list[rlcms.Composite] returns:     ee.Image</p> Source code in <code>src\\rlcms\\composites.py</code> <pre><code>def stack(composites:list):\n    \"\"\"\n    stacks a list of rlcms.Composites together, prefixing each band with the Composite's dataset name\n    args:\n        composites: list[rlcms.Composite]\n    returns:\n        ee.Image\n    \"\"\"\n    if len(composites) &lt; 2 or not all(isinstance(c,Composite) for c in composites):\n        raise ValueError(\"composites must be a list of 2 or more rlcms.Composites\")\n    else:\n        # returns list of ee.Images with renamed bands\n        renamed = [c.image.regexpRename('^', f\"{c.dataset.replace('/','_')}_\") for c in composites]\n        # stack renamed image list into one ee.Image\n        stacked = ee.Image.cat(renamed)\n        return stacked\n</code></pre>"},{"location":"covariates/","title":"covariates module","text":""},{"location":"covariates/#rlcms.covariates.indices","title":"<code>indices</code>","text":"Source code in <code>src\\rlcms\\covariates.py</code> <pre><code>class indices():\n\n\tdef __init__(self):\n\n\n\n\t\t# list with functions to call for each index\n\t\tself.functionList = {\"ND_blue_green\" : self.ND_blue_green, \\\n\t\t\t\t\t\t\t \"ND_blue_red\" : self.ND_blue_red, \\\n\t\t\t\t\t\t\t \"ND_blue_nir\" : self.ND_blue_nir, \\\n\t\t\t\t\t\t\t \"ND_blue_swir1\" : self.ND_blue_swir1, \\\n\t\t\t\t\t\t\t \"ND_blue_swir2\" : self.ND_blue_swir2, \\\n\t\t\t\t\t\t\t \"ND_green_red\" : self.ND_green_red, \\\n\t\t\t\t\t\t\t \"ND_green_nir\" : self.ND_green_nir, \\\n\t\t\t\t\t\t\t \"ND_green_swir1\" : self.ND_green_swir1, \\\n\t\t\t\t\t\t\t \"ND_green_swir2\" : self.ND_green_swir2, \\\n\t\t\t\t\t\t\t \"ND_red_swir1\" : self.ND_red_swir1, \\\n\t\t\t\t\t\t\t \"ND_red_swir2\" : self.ND_red_swir2, \\\n\t\t\t\t\t\t\t \"ND_nir_red\" : self.ND_nir_red, \\\n\t\t\t\t\t\t\t \"ND_nir_swir1\" : self.ND_nir_swir1, \\\n\t\t\t\t\t\t\t \"ND_nir_swir2\" : self.ND_nir_swir2, \\\n\t\t\t\t\t\t\t \"ND_swir1_swir2\" : self.ND_swir1_swir2, \\\n\t\t\t\t\t\t\t \"R_swir1_nir\" : self.R_swir1_nir, \\\n\t\t\t\t\t\t\t \"R_red_swir1\" : self.R_red_swir1, \\\n\t\t\t\t\t\t\t \"EVI\" : self.EVI, \\\n\t\t\t\t\t\t\t \"SAVI\" : self.SAVI, \\\n\t\t\t\t\t\t\t \"IBI\" : self.IBI}\n\n\n\tdef addAllTasselCapIndices(self,img): \n\t\t\"\"\" Function to get all tasselCap indices \"\"\"\n\n\t\tdef getTasseledCap(img):\n\t\t\t\"\"\"Function to compute the Tasseled Cap transformation and return an image\"\"\"\n\n\t\t\tcoefficients = ee.Array([\n\t\t\t\t[0.3037, 0.2793, 0.4743, 0.5585, 0.5082, 0.1863],\n\t\t\t\t[-0.2848, -0.2435, -0.5436, 0.7243, 0.0840, -0.1800],\n\t\t\t\t[0.1509, 0.1973, 0.3279, 0.3406, -0.7112, -0.4572],\n\t\t\t\t[-0.8242, 0.0849, 0.4392, -0.0580, 0.2012, -0.2768],\n\t\t\t\t[-0.3280, 0.0549, 0.1075, 0.1855, -0.4357, 0.8085],\n\t\t\t\t[0.1084, -0.9022, 0.4120, 0.0573, -0.0251, 0.0238]\n\t\t\t])\n\n\t\t\tbands=ee.List(['blue','green','red','nir','swir1','swir2'])\n\n\t\t\t# Make an Array Image, with a 1-D Array per pixel.\n\t\t\tarrayImage1D = img.select(bands).toArray()\n\n\t\t\t# Make an Array Image with a 2-D Array per pixel, 6x1.\n\t\t\tarrayImage2D = arrayImage1D.toArray(1)\n\n\t\t\tcomponentsImage = ee.Image(coefficients).matrixMultiply(arrayImage2D).arrayProject([0]).arrayFlatten([['brightness', 'greenness', 'wetness', 'fourth', 'fifth', 'sixth']]).float()\n\n\t\t\t# Get a multi-band image with TC-named bands.\n\t\t\treturn img.addBands(componentsImage);\t\n\n\n\t\tdef addTCAngles(img):\n\n\t\t\t\"\"\" Function to add Tasseled Cap angles and distances to an image. Assumes image has bands: 'brightness', 'greenness', and 'wetness'.\"\"\"\n\n\t\t\t# Select brightness, greenness, and wetness bands\t\n\t\t\tbrightness = img.select('brightness')\n\t\t\tgreenness = img.select('greenness')\n\t\t\twetness = img.select('wetness')\n\n\t\t\t# Calculate Tasseled Cap angles and distances\n\t\t\ttcAngleBG = brightness.atan2(greenness).divide(math.pi).rename(['tcAngleBG'])\n\t\t\ttcAngleGW = greenness.atan2(wetness).divide(math.pi).rename(['tcAngleGW'])\n\t\t\ttcAngleBW = brightness.atan2(wetness).divide(math.pi).rename(['tcAngleBW'])\n\t\t\ttcDistBG = brightness.hypot(greenness).rename(['tcDistBG'])\n\t\t\ttcDistGW = greenness.hypot(wetness).rename(['tcDistGW'])\n\t\t\ttcDistBW = brightness.hypot(wetness).rename(['tcDistBW'])\n\t\t\timg = img.addBands(tcAngleBG).addBands(tcAngleGW).addBands(tcAngleBW).addBands(tcDistBG).addBands(tcDistGW).addBands(tcDistBW)\n\n\t\t\treturn img\n\n\t\timg = getTasseledCap(img)\n\t\timg = addTCAngles(img)\n\t\treturn img\n\n\tdef ND_blue_green(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['blue','green']).rename(['ND_blue_green']))\n\t\treturn img\n\n\tdef ND_blue_red(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['blue','red']).rename(['ND_blue_red']))\n\t\treturn img\n\n\tdef ND_blue_nir(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['blue','nir']).rename(['ND_blue_nir']))\n\t\treturn img\n\n\tdef ND_blue_swir1(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['blue','swir1']).rename(['ND_blue_swir1']))\n\t\treturn img\n\n\tdef ND_blue_swir2(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['blue','swir2']).rename(['ND_blue_swir2']))\n\t\treturn img\n\n\tdef ND_green_red(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['green','red']).rename(['ND_green_red']))\n\t\treturn img\n\n\tdef ND_green_nir(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['green','nir']).rename(['ND_green_nir']))  # NDWBI\n\t\treturn img\n\n\tdef ND_green_swir1(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['green','swir1']).rename(['ND_green_swir1']))  # NDSI, MNDWI\n\t\treturn img\n\n\tdef ND_green_swir2(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['green','swir2']).rename(['ND_green_swir2']))\n\t\treturn img\n\n\tdef ND_red_swir1(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['red','swir1']).rename(['ND_red_swir1']))\n\t\treturn img\n\n\tdef ND_red_swir2(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['red','swir2']).rename(['ND_red_swir2']))\n\t\treturn img\n\n\tdef ND_nir_red(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['nir','red']).rename(['ND_nir_red']))  # NDVI\n\t\treturn img\n\n\tdef ND_nir_swir1(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['nir','swir1']).rename(['ND_nir_swir1']))  # NDWI, LSWI, -NDBI\n\t\treturn img\n\n\tdef ND_nir_swir2(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['nir','swir2']).rename(['ND_nir_swir2'])) # NBR, MNDVI\n\t\treturn img\n\n\tdef ND_swir1_swir2(self,img):\n\t\timg = img.addBands(img.normalizedDifference(['swir1','swir2']).rename(['ND_swir1_swir2']))\n\t\treturn img\n\n\tdef R_swir1_nir(self,img):\n\t\t# Add ratios\n\t\timg = img.addBands(img.select('swir1').divide(img.select('nir')).rename(['R_swir1_nir']));  # ratio 5/4\n\t\treturn img\n\n\tdef R_red_swir1(self,img):\n\t\timg = img.addBands(img.select('red').divide(img.select('swir1')).rename(['R_red_swir1']));  # ratio 3/5\n\t\treturn img\n\n\tdef EVI(self,img):\n\t\t#Add Enhanced Vegetation Index (EVI)\n\t\tevi = img.expression(\n\t\t\t'2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n\t\t\t  'NIR': img.select('nir'),\n\t\t\t  'RED': img.select('red'),\n\t\t\t  'BLUE': img.select('blue')\n\t\t  }).float()\n\n\t\timg = img.addBands(evi.rename(['EVI']))\n\n\t\treturn img\n\n\tdef SAVI(self,img):\n\t\t# Add Soil Adjust Vegetation Index (SAVI)\n\t\t# using L = 0.5;\n\t\tsavi = img.expression(\n\t\t\t'(NIR - RED) * (1 + 0.5)/(NIR + RED + 0.5)', {\n\t\t\t  'NIR': img.select('nir'),\n\t\t\t  'RED': img.select('red')\n\t\t  }).float()\n\t\timg = img.addBands(savi.rename(['SAVI']))\n\n\t\treturn img\n\n\tdef IBI(self,img):\n\t\t# Add Index-Based Built-Up Index (IBI)\n\t\tibi_a = img.expression(\n\t\t\t'2*SWIR1/(SWIR1 + NIR)', {\n\t\t\t  'SWIR1': img.select('swir1'),\n\t\t\t  'NIR': img.select('nir')\n\t\t\t}).rename(['IBI_A'])\n\n\n\t\tibi_b = img.expression(\n\t\t\t'(NIR/(NIR + RED)) + (GREEN/(GREEN + SWIR1))', {\n\t\t\t  'NIR': img.select('nir'),\n\t\t\t  'RED': img.select('red'),\n\t\t\t  'GREEN': img.select('green'),\n\t\t\t  'SWIR1': img.select('swir1')\n\t\t\t}).rename(['IBI_B'])\n\n\t\tibi_a = ibi_a.addBands(ibi_b)\n\t\tibi = ibi_a.normalizedDifference(['IBI_A','IBI_B'])\n\t\timg = img.addBands(ibi.rename(['IBI']))\n\n\t\treturn img\n\n\tdef addTopography(self,img): \n\t\t\"\"\"  Function to add 30m SRTM elevation and derived slope, aspect, eastness, and \n\t\tnorthness to an image. Elevation is in meters, slope is between 0 and 90 deg,\n\t\taspect is between 0 and 359 deg. Eastness and northness are unitless and are\n\t\tbetween -1 and 1. \"\"\"\n\n\t\t# Import SRTM elevation data\n\t\televation = ee.Image(\"USGS/SRTMGL1_003\")\n\n\t\t# Calculate slope, aspect, and hillshade\n\t\ttopo = ee.Algorithms.Terrain(elevation)\n\n\t\t# From aspect (a), calculate eastness (sin a), northness (cos a)\n\t\tdeg2rad = ee.Number(math.pi).divide(180)\n\t\taspect = topo.select(['aspect'])\n\t\taspect_rad = aspect.multiply(deg2rad)\n\t\teastness = aspect_rad.sin().rename(['eastness']).float()\n\t\tnorthness = aspect_rad.cos().rename(['northness']).float()\n\n\t\t# Add topography bands to image\n\t\ttopo = topo.select(['elevation','slope','aspect']).addBands(eastness).addBands(northness)\n\t\timg = img.addBands(topo)\n\t\treturn img\n\n\tdef addJRC(self,img):\n\t\t\"\"\" Function to add JRC Water layers: 'occurrence', 'change_abs', \n\t\t\t'change_norm', 'seasonality','transition', 'max_extent' \"\"\"\n\n\t\tjrcImage = ee.Image(\"JRC/GSW1_0/GlobalSurfaceWater\")\n\n\t\timg = img.addBands(jrcImage.select(['occurrence']).rename(['occurrence']))\n\t\timg = img.addBands(jrcImage.select(['change_abs']).rename(['change_abs']))\n\t\timg = img.addBands(jrcImage.select(['change_norm']).rename(['change_norm']))\n\t\timg = img.addBands(jrcImage.select(['seasonality']).rename(['seasonality']))\n\t\timg = img.addBands(jrcImage.select(['transition']).rename(['transition']))\n\t\timg = img.addBands(jrcImage.select(['max_extent']).rename(['max_extent']))\n\n\t\treturn img\n\n\n\tdef getIndices(self,img,covariates):\t\n\t\t\"\"\" add indices to image\"\"\"\n\t\t# self = indices()\n\t\t# no need to add indices that are already there\n\t\t# see TODO below, can't use removeDuplicates in .map()\n\t\t# indices = self.removeDuplicates(covariates,img.bandNames().getInfo())\n\t\tindices = covariates\n\n\t\tfor item in indices:\n\t\t\timg = self.functionList[item](img)\n\n\t\treturn img\n\n\tdef removeDuplicates(self,covariateList,bands):\n\t\t\"\"\" function to remove duplicates, i.e. existing bands do not need to be calculated \"\"\"\n\t\t# TODO: this does not scale to being mappable server side (can't use getInfo in mapped functions)\n\t\t# would need to EEify this logic to use with ee.List()'s\n\t\treturn [elem for elem in covariateList if elem not in bands]\n\n\tdef renameBands(self,image,prefix):\n\t\t\"\"\" renames bands with prefix \"\"\"\n\n\t\tbandnames = image.bandNames()\n\n\t\tdef mapBands(band):\n\t\t\tband = ee.String(prefix).cat('_').cat(band)\n\t\t\treturn band\n\n\t\tbandnames = bandnames.map(mapBands)\n\n\t\timage = image.rename(bandnames)\n\n\t\treturn image\n</code></pre>"},{"location":"covariates/#rlcms.covariates.indices.addAllTasselCapIndices","title":"<code>addAllTasselCapIndices(img)</code>","text":"<p>Function to get all tasselCap indices</p> Source code in <code>src\\rlcms\\covariates.py</code> <pre><code>def addAllTasselCapIndices(self,img): \n\t\"\"\" Function to get all tasselCap indices \"\"\"\n\n\tdef getTasseledCap(img):\n\t\t\"\"\"Function to compute the Tasseled Cap transformation and return an image\"\"\"\n\n\t\tcoefficients = ee.Array([\n\t\t\t[0.3037, 0.2793, 0.4743, 0.5585, 0.5082, 0.1863],\n\t\t\t[-0.2848, -0.2435, -0.5436, 0.7243, 0.0840, -0.1800],\n\t\t\t[0.1509, 0.1973, 0.3279, 0.3406, -0.7112, -0.4572],\n\t\t\t[-0.8242, 0.0849, 0.4392, -0.0580, 0.2012, -0.2768],\n\t\t\t[-0.3280, 0.0549, 0.1075, 0.1855, -0.4357, 0.8085],\n\t\t\t[0.1084, -0.9022, 0.4120, 0.0573, -0.0251, 0.0238]\n\t\t])\n\n\t\tbands=ee.List(['blue','green','red','nir','swir1','swir2'])\n\n\t\t# Make an Array Image, with a 1-D Array per pixel.\n\t\tarrayImage1D = img.select(bands).toArray()\n\n\t\t# Make an Array Image with a 2-D Array per pixel, 6x1.\n\t\tarrayImage2D = arrayImage1D.toArray(1)\n\n\t\tcomponentsImage = ee.Image(coefficients).matrixMultiply(arrayImage2D).arrayProject([0]).arrayFlatten([['brightness', 'greenness', 'wetness', 'fourth', 'fifth', 'sixth']]).float()\n\n\t\t# Get a multi-band image with TC-named bands.\n\t\treturn img.addBands(componentsImage);\t\n\n\n\tdef addTCAngles(img):\n\n\t\t\"\"\" Function to add Tasseled Cap angles and distances to an image. Assumes image has bands: 'brightness', 'greenness', and 'wetness'.\"\"\"\n\n\t\t# Select brightness, greenness, and wetness bands\t\n\t\tbrightness = img.select('brightness')\n\t\tgreenness = img.select('greenness')\n\t\twetness = img.select('wetness')\n\n\t\t# Calculate Tasseled Cap angles and distances\n\t\ttcAngleBG = brightness.atan2(greenness).divide(math.pi).rename(['tcAngleBG'])\n\t\ttcAngleGW = greenness.atan2(wetness).divide(math.pi).rename(['tcAngleGW'])\n\t\ttcAngleBW = brightness.atan2(wetness).divide(math.pi).rename(['tcAngleBW'])\n\t\ttcDistBG = brightness.hypot(greenness).rename(['tcDistBG'])\n\t\ttcDistGW = greenness.hypot(wetness).rename(['tcDistGW'])\n\t\ttcDistBW = brightness.hypot(wetness).rename(['tcDistBW'])\n\t\timg = img.addBands(tcAngleBG).addBands(tcAngleGW).addBands(tcAngleBW).addBands(tcDistBG).addBands(tcDistGW).addBands(tcDistBW)\n\n\t\treturn img\n\n\timg = getTasseledCap(img)\n\timg = addTCAngles(img)\n\treturn img\n</code></pre>"},{"location":"covariates/#rlcms.covariates.indices.addJRC","title":"<code>addJRC(img)</code>","text":"<p>Function to add JRC Water layers: 'occurrence', 'change_abs',  'change_norm', 'seasonality','transition', 'max_extent'</p> Source code in <code>src\\rlcms\\covariates.py</code> <pre><code>def addJRC(self,img):\n\t\"\"\" Function to add JRC Water layers: 'occurrence', 'change_abs', \n\t\t'change_norm', 'seasonality','transition', 'max_extent' \"\"\"\n\n\tjrcImage = ee.Image(\"JRC/GSW1_0/GlobalSurfaceWater\")\n\n\timg = img.addBands(jrcImage.select(['occurrence']).rename(['occurrence']))\n\timg = img.addBands(jrcImage.select(['change_abs']).rename(['change_abs']))\n\timg = img.addBands(jrcImage.select(['change_norm']).rename(['change_norm']))\n\timg = img.addBands(jrcImage.select(['seasonality']).rename(['seasonality']))\n\timg = img.addBands(jrcImage.select(['transition']).rename(['transition']))\n\timg = img.addBands(jrcImage.select(['max_extent']).rename(['max_extent']))\n\n\treturn img\n</code></pre>"},{"location":"covariates/#rlcms.covariates.indices.addTopography","title":"<code>addTopography(img)</code>","text":"<p>Function to add 30m SRTM elevation and derived slope, aspect, eastness, and  northness to an image. Elevation is in meters, slope is between 0 and 90 deg, aspect is between 0 and 359 deg. Eastness and northness are unitless and are between -1 and 1.</p> Source code in <code>src\\rlcms\\covariates.py</code> <pre><code>def addTopography(self,img): \n\t\"\"\"  Function to add 30m SRTM elevation and derived slope, aspect, eastness, and \n\tnorthness to an image. Elevation is in meters, slope is between 0 and 90 deg,\n\taspect is between 0 and 359 deg. Eastness and northness are unitless and are\n\tbetween -1 and 1. \"\"\"\n\n\t# Import SRTM elevation data\n\televation = ee.Image(\"USGS/SRTMGL1_003\")\n\n\t# Calculate slope, aspect, and hillshade\n\ttopo = ee.Algorithms.Terrain(elevation)\n\n\t# From aspect (a), calculate eastness (sin a), northness (cos a)\n\tdeg2rad = ee.Number(math.pi).divide(180)\n\taspect = topo.select(['aspect'])\n\taspect_rad = aspect.multiply(deg2rad)\n\teastness = aspect_rad.sin().rename(['eastness']).float()\n\tnorthness = aspect_rad.cos().rename(['northness']).float()\n\n\t# Add topography bands to image\n\ttopo = topo.select(['elevation','slope','aspect']).addBands(eastness).addBands(northness)\n\timg = img.addBands(topo)\n\treturn img\n</code></pre>"},{"location":"covariates/#rlcms.covariates.indices.getIndices","title":"<code>getIndices(img, covariates)</code>","text":"<p>add indices to image</p> Source code in <code>src\\rlcms\\covariates.py</code> <pre><code>def getIndices(self,img,covariates):\t\n\t\"\"\" add indices to image\"\"\"\n\t# self = indices()\n\t# no need to add indices that are already there\n\t# see TODO below, can't use removeDuplicates in .map()\n\t# indices = self.removeDuplicates(covariates,img.bandNames().getInfo())\n\tindices = covariates\n\n\tfor item in indices:\n\t\timg = self.functionList[item](img)\n\n\treturn img\n</code></pre>"},{"location":"covariates/#rlcms.covariates.indices.removeDuplicates","title":"<code>removeDuplicates(covariateList, bands)</code>","text":"<p>function to remove duplicates, i.e. existing bands do not need to be calculated</p> Source code in <code>src\\rlcms\\covariates.py</code> <pre><code>def removeDuplicates(self,covariateList,bands):\n\t\"\"\" function to remove duplicates, i.e. existing bands do not need to be calculated \"\"\"\n\t# TODO: this does not scale to being mappable server side (can't use getInfo in mapped functions)\n\t# would need to EEify this logic to use with ee.List()'s\n\treturn [elem for elem in covariateList if elem not in bands]\n</code></pre>"},{"location":"covariates/#rlcms.covariates.indices.renameBands","title":"<code>renameBands(image, prefix)</code>","text":"<p>renames bands with prefix</p> Source code in <code>src\\rlcms\\covariates.py</code> <pre><code>def renameBands(self,image,prefix):\n\t\"\"\" renames bands with prefix \"\"\"\n\n\tbandnames = image.bandNames()\n\n\tdef mapBands(band):\n\t\tband = ee.String(prefix).cat('_').cat(band)\n\t\treturn band\n\n\tbandnames = bandnames.map(mapBands)\n\n\timage = image.rename(bandnames)\n\n\treturn image\n</code></pre>"},{"location":"covariates/#rlcms.covariates.returnCovariates","title":"<code>returnCovariates(img)</code>","text":"<p>Workflow for computing Landsat and covariates. bands and covariates are hardcoded inside the function.</p> Source code in <code>src\\rlcms\\covariates.py</code> <pre><code>def returnCovariates(img):\n\t\"\"\"Workflow for computing Landsat and covariates. bands and covariates are hardcoded inside the function.\"\"\"\n\t# hard coded for now\n\tbands = ['blue','green','red','nir','swir1', 'swir2']\t\n\tbandLow = ['p20_blue','p20_green','p20_red','p20_nir','p20_swir1', 'p20_swir2']\n\tbandHigh = ['p80_blue','p80_green','p80_red','p80_nir','p80_swir1', 'p80_swir2']\n\n\t\"\"\"Calculate the urban, builtup cropland rice and barren primitives \"\"\"\n\tcovariates = [\"ND_blue_green\",\"ND_blue_red\",\"ND_blue_nir\",\"ND_blue_swir1\",\"ND_blue_swir2\", \\\n\t\t\t\t  \"ND_green_red\",\"ND_green_nir\",\"ND_green_swir1\",\"ND_green_swir2\",\"ND_red_swir1\",\\\n\t\t\t\t  \"ND_red_swir2\",\"ND_nir_red\",\"ND_nir_swir1\",\"ND_nir_swir2\",\"ND_swir1_swir2\",\\\n\t\t\t\t  \"R_swir1_nir\",\"R_red_swir1\",\"EVI\",\"SAVI\",\"IBI\"]\n\n\tindex = indices()\n\n\tdef scaleLandsat(img):\n\t\t\"\"\"Landast is scaled by factor 0.0001 \"\"\"\n\t\tthermalBand = ee.List(['thermal'])\n\t\tthermal = ee.Image(img).select(thermalBand).divide(10)\n\n\t\totherBands = ee.Image(img).bandNames().removeAll(thermalBand)\n\n\t\tscaled = ee.Image(img).select(otherBands).multiply(0.0001)\n\t\timage = ee.Image(scaled.addBands(thermal))        \n\n\t\treturn ee.Image(image.copyProperties(img))\n\n\timg = scaleLandsat(img)\n\n\tdef addIndices(img,prefix):\n\t\timg = index.addAllTasselCapIndices(img)\n\t\timg = index.getIndices(img,covariates)\n\t\timg = index.addJRC(img).unmask(0)\n\t\timg = index.addTopography(img).unmask(0)\t\n\t\tif len(prefix) &gt; 0:\t\n\t\t\timg = index.renameBands(img,prefix)\n\t\treturn img\n\n\n\tdown = addIndices(img.select(bandLow,bands),\"p20\")\n\tmiddle = addIndices(img.select(bands),\"\")\n\tup = addIndices(img.select(bandHigh,bands),\"p80\")\n\n\timg = down.addBands(middle).addBands(up)\n\n\treturn img\n</code></pre>"},{"location":"covariates/#rlcms.covariates.returnCovariatesFromOptions","title":"<code>returnCovariatesFromOptions(img, **kwargs)</code>","text":"<p>Computes and adds image covariates according to user settings args:         img (ee.Image): image to compute covariates          kwargs (dict): a settings dictionary  returns:         img (ee.Image): multi-band image with all desired covariates</p> Source code in <code>src\\rlcms\\covariates.py</code> <pre><code>def returnCovariatesFromOptions(img,**kwargs):\n\t\"\"\"\n\tComputes and adds image covariates according to user settings\n\targs:\n\t\timg (ee.Image): image to compute covariates \n\t\tkwargs (dict): a settings dictionary \n\treturns:\n\t\timg (ee.Image): multi-band image with all desired covariates\n\t\"\"\"\n\tsettings = kwargs\n\tif 'indices' in kwargs.keys():\n\t\tif len(kwargs['indices']) &gt; 0:\n\t\t\tcovariates = settings['indices']\n\t\t\tindex = indices()\n\n\t\timg = ee.Image(img)\n\t\timg = index.getIndices(img,covariates)\n\n\tif 'addTasselCap' in kwargs.keys():\n\t\tif kwargs['addTasselCap']:\n\t\t\timg = index.addAllTasselCapIndices(img)\n\n\treturn img\n</code></pre>"},{"location":"harmonics/","title":"harmonics module","text":""},{"location":"harmonics/#rlcms.harmonics.addHarmonicTerms","title":"<code>addHarmonicTerms(image)</code>","text":"<p>add Time bands to image</p> Source code in <code>src\\rlcms\\harmonics.py</code> <pre><code>def addHarmonicTerms(image):\n    \"\"\"add Time bands to image\"\"\"\n    timeRadians = image.select(\"t\").multiply(2 * math.pi)\n    return image.addBands(timeRadians.cos().rename(\"cos\")).addBands(\n        timeRadians.sin().rename(\"sin\")\n    )\n</code></pre>"},{"location":"harmonics/#rlcms.harmonics.addTimeConstant","title":"<code>addTimeConstant(imageCollection, timeField)</code>","text":"<p>Add time constant to images in an ImageCollection timeField: time stamp property name (typically is the 'system:time_start' property of an image)</p> Source code in <code>src\\rlcms\\harmonics.py</code> <pre><code>def addTimeConstant(imageCollection: ee.ImageCollection, timeField: str):\n    \"\"\"\n    Add time constant to images in an ImageCollection\n    timeField: time stamp property name (typically is the 'system:time_start' property of an image)\n    \"\"\"\n    def _(image, timeField):\n        # // Compute time in fractional years since the epoch.\n        date = ee.Date(image.get(timeField))\n        years = date.difference(ee.Date(\"1970-01-01\"), \"year\")\n        # // Return the image with the added bands.\n        return image.addBands(ee.Image(years).rename(\"t\").float()).addBands(\n            ee.Image.constant(1)\n        )\n\n    return imageCollection.map(lambda i: _(i, timeField))\n</code></pre>"},{"location":"harmonics/#rlcms.harmonics.calculateHarmonic","title":"<code>calculateHarmonic(imageCollection, dependent)</code>","text":"<p>Calculate harmonic coefficients (phase and amplitude) off of an ImageCollection dependent: band that you fit the harmonic model for, must be contained in ImageCollection</p> Source code in <code>src\\rlcms\\harmonics.py</code> <pre><code>def calculateHarmonic(imageCollection: ee.ImageCollection, dependent: ee.String):\n    \"\"\"\n    Calculate harmonic coefficients (phase and amplitude) off of an ImageCollection\n    dependent: band that you fit the harmonic model for, must be contained in ImageCollection\n    \"\"\"\n    harmonicIndependents = ee.List([\"constant\", \"t\", \"cos\", \"sin\"])\n    #  Add harmonic terms as new image bands.\n    harmonicLandsat = imageCollection.map(addHarmonicTerms)\n    # The output of the regression reduction is a 4x1 array image.\n    harmonicTrend = harmonicLandsat.select(harmonicIndependents.add(dependent)).reduce(\n        ee.Reducer.linearRegression(harmonicIndependents.length(), 1)\n    )\n\n    # Turn the array image into a multi-band image of coefficients.\n    harmonicTrendCoefficients = (\n        harmonicTrend.select(\"coefficients\")\n        .arrayProject([0])\n        .arrayFlatten([harmonicIndependents])\n    )\n\n    # // Compute phase and amplitude.\n    phase = (\n        harmonicTrendCoefficients.select(\"cos\")\n        .atan2(harmonicTrendCoefficients.select(\"sin\"))\n        .rename(dependent.cat(\"_phase\"))\n    )\n\n    amplitude = (\n        harmonicTrendCoefficients.select(\"cos\")\n        .hypot(harmonicTrendCoefficients.select(\"sin\"))\n        .rename(dependent.cat(\"_amplitude\"))\n    )\n    return ee.Image.cat(phase, amplitude)\n</code></pre>"},{"location":"harmonics/#rlcms.harmonics.doHarmonicsFromOptions","title":"<code>doHarmonicsFromOptions(imgColl, **kwargs)</code>","text":"<p>calculateHarmonic function band-wise</p> <p>kwargs:     harmonicsOptions (dict): which band(s) and the DOY start and end date to compute harmonics on         formatted like:          {             'red':{'start':1,'end':365},             'blue':{'start':1,'end':365}             } returns:     ee.Image containing bands [band_phase, band_amplitude]</p> Source code in <code>src\\rlcms\\harmonics.py</code> <pre><code>def doHarmonicsFromOptions(imgColl:ee.ImageCollection,**kwargs):\n    \"\"\"\n    calculateHarmonic function band-wise\n\n    args:\n        imgColl (ee.ImageCollection)\n    kwargs:\n        harmonicsOptions (dict): which band(s) and the DOY start and end date to compute harmonics on\n            formatted like: \n            {\n                'red':{'start':1,'end':365},\n                'blue':{'start':1,'end':365}\n                }\n    returns:\n        ee.Image containing bands [band_phase, band_amplitude]\n    \"\"\"\n    imgColl = ee.ImageCollection(imgColl)\n    harmonicsOptions = kwargs['harmonicsOptions']\n\n    # get harmonicsOptions dictionary\n    if isinstance(harmonicsOptions,dict):\n\n        # get band keys as list\n        bands = ee.Dictionary(harmonicsOptions).keys()\n\n        def harmonicByBand(band):\n            band = ee.String(band)\n            # get the params for that band\n            bandwiseParams = ee.Dictionary(harmonicsOptions).get(band)\n\n            # get the start and end DOY parameters\n            start = ee.Dictionary(bandwiseParams).get('start')\n            end = ee.Dictionary(bandwiseParams).get('end')\n\n            # create temporal filtered imgColl for that band\n            imgCollByBand = (ee.ImageCollection(imgColl)\n                                .select(band)\n                                .filter(ee.Filter.dayOfYear(start,end)))\n            # add time bands\n            timeField = \"system:time_start\"\n            timeCollection = addTimeConstant(imgCollByBand, timeField)\n\n            return ee.Image(calculateHarmonic(timeCollection,band))\n    else:\n        raise TypeError(f\"harmonicsOptions expects dict type, got: {type(harmonicsOptions)}\")\n\n    # do harmonics by band key in model_inputs dictionary\n    listOfImages = ee.Image.cat(ee.List(bands).map(harmonicByBand))\n    bandStack = ee.Image(ee.ImageCollection.fromImages(listOfImages).toBands())\n\n    # to remove srcImg band name indexing resulting from .toBands() \n    # (i.e. [0_swir1_phase, 0_swir1_amplitude] -&gt; [swir1_phase, swir1_amplitude] )\n    bandNames = bandStack.bandNames()\n    fixedBandNames = bandNames.map(lambda e: ee.String(e).split(\"_\").slice(-2).join(\"_\"))\n    return bandStack.rename(fixedBandNames)\n</code></pre>"},{"location":"harmonics/#rlcms.harmonics.harmonicRGB","title":"<code>harmonicRGB(harmonics)</code>","text":"<p>Use the HSV to RGB transform to display phase and amplitude</p> Source code in <code>src\\rlcms\\harmonics.py</code> <pre><code>def harmonicRGB(harmonics: ee.Image):\n    \"\"\"Use the HSV to RGB transform to display phase and amplitude\"\"\"\n    amplitude = harmonics.select(\".*amplitude\")\n    phase = harmonics.select(\".*phase\")\n\n    rgb = (\n        phase.unitScale(-math.pi, math.pi)\n        .addBands(amplitude.multiply(2.5))\n        .addBands(ee.Image(1))\n        .hsvToRgb()\n    )\n    return rgb\n</code></pre>"},{"location":"primitives/","title":"primitives module","text":""},{"location":"primitives/#rlcms.primitives.Primitives","title":"<code>Primitives</code>","text":"Source code in <code>src\\rlcms\\primitives.py</code> <pre><code>class Primitives:\n    def __init__(self,\n                 inputs=None,\n                 training=None,\n                 class_name=None,\n                 asset_id=None):\n        \"\"\"\n        Construct a Primitives ensemble, provided an input ee.Image stack containing feature bands and a training point FeatureCollection\n        NOTE: land cover typology in your training dataset should be alpha-numerically sorted (Agriculture: 1, Bare Soil: 2, Built: 3) and should not skip label values (1,2,4,5). There may be unexpected results if this is not handled properly first by the user.\n\n        Args:\n            inputs (str|ee.Image): input image stack\n            training (str|ee.FeatureCollection): training data\n            class_name (str): class property containing class labels (i.e. 1, 2, 3), currently only 'LANDCOVER' is supported\n            asset_id (str): Optional, GEE asset path to pre-existing Primitives ee.ImageCollection. Useful for exporting intermediary output approach\n\n        Returns: \n            Primitives object\n        \"\"\"\n\n        # TODO: perform some checks and error handling for training point label formatting \n        def pre_format_pts(pts,class_name):\n            # two things: \n            # 1. need to ensure that 'LANDCOVER' is the class_name, if not, set new property in each feature using that\n            if class_name != 'LANDCOVER':\n                # set user's class_name to 'LANDCOVER' so we don't need to pass custom class_name around to every function\n                pts = pts.map(lambda p: p.set('LANDCOVER',p.get(class_name)))\n            else:\n                # check 'LANDCOVER' is a property in collection\n                assert 'LANDCOVER' in pts.first().propertyNames().getInfo(), \"'LANDCOVER' is not a property in the collection\"\n            # 2. ensure that value of 'LANDCOVER' is integer before converting to string\n            def to_int(p):\n                val = p.get('LANDCOVER')\n                # is 'LANDCOVER' always going to be string? can we convert it to string without first knowing if its String or Number?\n                int_val = ee.Number(val).round()\n                return p.set('LANDCOVER',int_val)\n            return pts.map(to_int)\n\n        def format_pts(pts):\n            \"\"\"Turn a FC of training points containing full LC typology into a list of primitive point FCs, \n                    one point FC for each LC primitive\"\"\"\n            # create sets of binary training pts for each class represented in the full training pts collection\n            labels = ee.FeatureCollection(pts).aggregate_array('LANDCOVER').distinct().sort()\n            def binaryPts(l):\n                # create prim and non prim sets with filters, reset prim to 1, non-prim to 0\n                prim = pts.filter(ee.Filter.eq('LANDCOVER',l)).map(lambda f: f.set('PRIM',1))\n                non_prim = pts.filter(ee.Filter.neq('LANDCOVER',l)).map(lambda f: f.set('PRIM',0))\n                return ee.FeatureCollection(prim).merge(non_prim)\n            list_of_prim_pts = ee.List(labels).map(binaryPts)\n            return list_of_prim_pts\n\n        def gettop20(dict):\n            # if total input features count &lt; 20, take them all, otherwise take top 20 most important\n            dict = ee.Dictionary(dict)\n            values = dict.values().sort()\n            cutoff = ee.Algorithms.If(values.size().gte(20),-20,values.size().multiply(-1))\n            def kv_return(key,passedObj):\n                passedObj = ee.List(passedObj)\n                val = ee.Number(dict.get(key))\n                retObj = ee.Algorithms.If(val.gte(cutoff),passedObj.add(key),passedObj)\n                return retObj\n            newl = dict.keys().iterate(kv_return,ee.List([]))\n            return newl\n\n        def RFprim(training_pts,input_stack):\n            \"\"\"Train and apply RF Probability classifier on a Primitive\"\"\"\n            inputs = ee.Image(input_stack)\n            samples = ee.FeatureCollection(training_pts)\n\n            class_value = ee.Number(ee.Feature(samples.sort('PRIM',False).first()).get('LANDCOVER')) #get LC numeric value for the given primitive (i.e. 'PRIM':1, 'LANDCOVER':6) then map to its class label (i.e. 6: 'Water')\n\n            # can experiment with classifier params for model performance\n            classifier = ee.Classifier.smileRandomForest(\n            numberOfTrees=100, \n            minLeafPopulation=1, \n            bagFraction=0.7, \n            seed=51515).setOutputMode('PROBABILITY')\n\n            # train model with all features\n            model = classifier.train(features=samples, \n                                    classProperty='PRIM', \n                                    inputProperties=inputs.bandNames() \n                                    )\n\n            # store for model performance exploration\n            oob_all = ee.Dictionary(model.explain()).get('outOfBagErrorEstimate')\n            importance_all = ee.Dictionary(model.explain()).get('importance')\n\n            # retrieve top 20 most important features\n            top20 = gettop20(importance_all)\n\n            # re-train model with top20 important features\n            model = classifier.train(features=samples, \n                                    classProperty='PRIM', \n                                    inputProperties=top20\n                                    )\n\n            oob_top20 = ee.Dictionary(model.explain()).get('outOfBagErrorEstimate')\n            importance_top20 = ee.Dictionary(model.explain()).get('importance')\n            schema = ee.List(ee.Classifier(model).schema())\n            output = (ee.Image(inputs)\n                      .classify(model,'Probability')\n                      # lists and dictionaries do not propagate thru as properties on Batch exported Images\n                      .set('Primitive',class_value,\n                           'importance',importance_top20, \n                           'schema',schema, \n                           'model',model,\n                           'oobError',oob_top20, \n                           ))\n            return output\n\n        def primitives_to_collection(input_stack,\n                                     training_pts,\n                                     class_name):\n            \"\"\"\n            Create LC Primitive image for each LC class in training points\n\n            args:\n                input_stack (ee.Image): of all covariates and predictor\n                training_pts (ee.FeatureCollection): training pts containing full LC typology\n                class_name (str): property name in training points containing model classes\n\n            returns:\n                ee.ImageCollection of Primitive ee.Images\n            \"\"\"\n\n            input_stack = ee.Image(input_stack)\n            training_pts = ee.FeatureCollection(training_pts)\n\n            # list of distinct LANDCOVER values\n            labels = training_pts.aggregate_array(class_name).distinct().sort().getInfo() # .sort() should fix Prims exporting out of order (i.e. 2,3,4,7,6)\n\n            # converting to index of the list of distinct LANDCOVER primtive FC's (prim_pts below)\n            indices = list(range(len(labels))) # handles dynamic land cover strata\n\n            prim_list = []\n            for i in indices: # running one LC class at a time\n                prim_pts = ee.FeatureCollection(ee.List(format_pts(training_pts)).get(i)) # format training pts to 1/0 prim format\n                img = RFprim(prim_pts,input_stack) # run RF primitive model, get output image and metrics\n                prim_list.append(img)\n\n            return ee.ImageCollection.fromImages(prim_list)\n\n        # you can construct Primitives object from a pre-existing Primitives ImgColl\n        if asset_id != None:\n            try:\n                primitives = ee.ImageCollection(asset_id)\n                self.collection = primitives\n                self.region = primitives.first().geometry().getInfo()\n                self.training_data = None\n            except: \n                raise(EEException)\n        else:\n            primitives = primitives_to_collection(inputs,training,class_name)\n            self.collection = primitives\n            self.region = ee.Image(inputs).geometry().getInfo()\n            self.training_data = ee.FeatureCollection(training)\n\n    def assemble_max_probability(self):\n        \"\"\"\n        Take Image Collection of RF Primitives, perform pixel-wise maximum of all Primitive probability images to return single-band LC image\n        Array computation returns img values from 0 to n-1 due to 0-base indexing, so we .add(1) to match LC strata\n\n        Args:\n            image: multiband image of probabilities\n            remapNum: list, list of intergers 0-N matching the number of probability bands\n            originalNum: list, list of inergers n-N matching the number of probability bands\n                        that represent their desired map values\n\n        Returns: ee.Image of Land Cover                            \n        \"\"\"\n        def max_prob(image):\n\n            maxProbClassification = (image.toArray()\n                                    .arrayArgmax()\n                                    .arrayFlatten([['classification']])\n                                    .rename('classification')\n                                    )\n            return maxProbClassification\n\n        image  = self.collection.toBands()\n        max_probability = max_prob(image)\n        output = max_probability.add(1).rename('LANDCOVER')\n        return output\n\n    def export_metrics(self,metrics_path):\n            \"\"\"\n            Parse variable importance and OOB Error estimate from trained model, output to local files respectively\n            Currently only works for Primitives objects in memory (not loaded from pre-existing ImgColl)\n            \"\"\"\n            # Var Importance to csv file\n            imgColl = self.collection\n            to_list = ee.List(imgColl.toList(imgColl.size()))\n            for i in list(range(imgColl.size().getInfo())):\n                img = ee.Image(to_list.get(i))\n                prim_value = str(img.get('Primitive').getInfo())\n\n                # Variable Importance to .csv\n                dct = ee.Dictionary(img.get('importance')).getInfo()\n                _list = dct.values()\n                idx = dct.keys()\n                df = pd.DataFrame(_list, index = idx)\n                df.to_csv(os.path.join(metrics_path,f\"varImportancePrimitive{prim_value}.csv\"))\n\n                # OOB error to .txt file\n                oob = img.get('oobError')\n                with open(os.path.join(metrics_path,f'oobErrorPrimitive{prim_value}.txt'),mode='w') as f:\n                    f.write(ee.String(ee.Number(oob).format()).getInfo())\n                    f.close()\n\n    def export_to_asset(self,\n                        collection_assetId=None,\n                        scale=None,\n                        crs=None,\n                        crsTransform=None,\n                        maxPixels=None,\n                        **kwargs):\n        \"\"\"\n        Export Primitives to Asset as an ImageCollection\n\n        Args:\n            collection_assetId (str): output ImageCollection asset path \n            scale (int): export scale\n            crs (str): export CRS ('EPSG:4326')\n            crsTransform (list): export CRS Transform\n            maxPixels (int): max Pixels\n\n        Returns: \n            None, Submits all Export Image tasks for Primitive collection\n        \"\"\"\n\n        # make the empty IC\n        print(f\"Creating empty Primitives ImageCollection: {collection_assetId}.\\n\")\n        os.popen(f\"earthengine create collection {collection_assetId}\").read()\n        prims_count = self.collection.size().getInfo()\n        prims_list = ee.ImageCollection(self.collection).toList(prims_count)\n        aoi = ee.Image(prims_list.get(0)).geometry()\n        for i in list(range(prims_count)):\n            prim = ee.Image(prims_list.get(i))\n            desc = f\"Primitive{str(ee.Image(prim).get('Primitive').getInfo())}\" # this would need to be defined in the Prims img for-loop\n            asset_id = f'{collection_assetId}/{desc}'\n            export_img_to_asset(image=prim,\n                                description=desc,\n                                assetId=asset_id,\n                                region=aoi,\n                                scale=scale,\n                                crs=crs,\n                                crsTransform=None,\n                                maxPixels=1e13)\n\n        return\n\n    def export_to_drive(self,\n                        description,\n                        folder,\n                        fileNamePrefix,\n                        dimensions=None,\n                        region=None,\n                        scale=None,\n                        crs=None,\n                        crsTransform=None,\n                        maxPixels=None,\n                        shardSize=None,\n                        fileDimensions=None,\n                        skipEmptyTiles=None,\n                        fileFormat=None,\n                        formatOptions=None,\n                        **kwargs,):\n        \"\"\"\n        Export Primitives to Drive as a Multi-band GeoTiff\n\n        See rlcms.utils.export_img_to_drive() docs for Args\n\n        Returns: \n            None, Submits all Export Image tasks for Primitive collection\n        \"\"\"\n\n        prim_img = self.collection.toBands()\n        export_image_to_drive(image=prim_img,\n                                description=description,\n                                folder=folder,\n                                fileNamePrefix=fileNamePrefix,\n                                dimensions=dimensions,\n                                region=region,\n                                scale=scale,\n                                crs=crs,\n                                crsTransform=crsTransform,\n                                maxPixels=maxPixels,\n                                shardSize=shardSize,\n                                fileDimensions=fileDimensions,\n                                skipEmptyTiles=skipEmptyTiles,\n                                fileFormat=fileFormat,\n                                formatOptions=formatOptions,\n                                **kwargs,)\n        return\n</code></pre>"},{"location":"primitives/#rlcms.primitives.Primitives.__init__","title":"<code>__init__(inputs=None, training=None, class_name=None, asset_id=None)</code>","text":"<p>Construct a Primitives ensemble, provided an input ee.Image stack containing feature bands and a training point FeatureCollection NOTE: land cover typology in your training dataset should be alpha-numerically sorted (Agriculture: 1, Bare Soil: 2, Built: 3) and should not skip label values (1,2,4,5). There may be unexpected results if this is not handled properly first by the user.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>str | Image</code> <p>input image stack</p> <code>None</code> <code>training</code> <code>str | FeatureCollection</code> <p>training data</p> <code>None</code> <code>class_name</code> <code>str</code> <p>class property containing class labels (i.e. 1, 2, 3), currently only 'LANDCOVER' is supported</p> <code>None</code> <code>asset_id</code> <code>str</code> <p>Optional, GEE asset path to pre-existing Primitives ee.ImageCollection. Useful for exporting intermediary output approach</p> <code>None</code> <p>Returns:</p> Type Description <p>Primitives object</p> Source code in <code>src\\rlcms\\primitives.py</code> <pre><code>def __init__(self,\n             inputs=None,\n             training=None,\n             class_name=None,\n             asset_id=None):\n    \"\"\"\n    Construct a Primitives ensemble, provided an input ee.Image stack containing feature bands and a training point FeatureCollection\n    NOTE: land cover typology in your training dataset should be alpha-numerically sorted (Agriculture: 1, Bare Soil: 2, Built: 3) and should not skip label values (1,2,4,5). There may be unexpected results if this is not handled properly first by the user.\n\n    Args:\n        inputs (str|ee.Image): input image stack\n        training (str|ee.FeatureCollection): training data\n        class_name (str): class property containing class labels (i.e. 1, 2, 3), currently only 'LANDCOVER' is supported\n        asset_id (str): Optional, GEE asset path to pre-existing Primitives ee.ImageCollection. Useful for exporting intermediary output approach\n\n    Returns: \n        Primitives object\n    \"\"\"\n\n    # TODO: perform some checks and error handling for training point label formatting \n    def pre_format_pts(pts,class_name):\n        # two things: \n        # 1. need to ensure that 'LANDCOVER' is the class_name, if not, set new property in each feature using that\n        if class_name != 'LANDCOVER':\n            # set user's class_name to 'LANDCOVER' so we don't need to pass custom class_name around to every function\n            pts = pts.map(lambda p: p.set('LANDCOVER',p.get(class_name)))\n        else:\n            # check 'LANDCOVER' is a property in collection\n            assert 'LANDCOVER' in pts.first().propertyNames().getInfo(), \"'LANDCOVER' is not a property in the collection\"\n        # 2. ensure that value of 'LANDCOVER' is integer before converting to string\n        def to_int(p):\n            val = p.get('LANDCOVER')\n            # is 'LANDCOVER' always going to be string? can we convert it to string without first knowing if its String or Number?\n            int_val = ee.Number(val).round()\n            return p.set('LANDCOVER',int_val)\n        return pts.map(to_int)\n\n    def format_pts(pts):\n        \"\"\"Turn a FC of training points containing full LC typology into a list of primitive point FCs, \n                one point FC for each LC primitive\"\"\"\n        # create sets of binary training pts for each class represented in the full training pts collection\n        labels = ee.FeatureCollection(pts).aggregate_array('LANDCOVER').distinct().sort()\n        def binaryPts(l):\n            # create prim and non prim sets with filters, reset prim to 1, non-prim to 0\n            prim = pts.filter(ee.Filter.eq('LANDCOVER',l)).map(lambda f: f.set('PRIM',1))\n            non_prim = pts.filter(ee.Filter.neq('LANDCOVER',l)).map(lambda f: f.set('PRIM',0))\n            return ee.FeatureCollection(prim).merge(non_prim)\n        list_of_prim_pts = ee.List(labels).map(binaryPts)\n        return list_of_prim_pts\n\n    def gettop20(dict):\n        # if total input features count &lt; 20, take them all, otherwise take top 20 most important\n        dict = ee.Dictionary(dict)\n        values = dict.values().sort()\n        cutoff = ee.Algorithms.If(values.size().gte(20),-20,values.size().multiply(-1))\n        def kv_return(key,passedObj):\n            passedObj = ee.List(passedObj)\n            val = ee.Number(dict.get(key))\n            retObj = ee.Algorithms.If(val.gte(cutoff),passedObj.add(key),passedObj)\n            return retObj\n        newl = dict.keys().iterate(kv_return,ee.List([]))\n        return newl\n\n    def RFprim(training_pts,input_stack):\n        \"\"\"Train and apply RF Probability classifier on a Primitive\"\"\"\n        inputs = ee.Image(input_stack)\n        samples = ee.FeatureCollection(training_pts)\n\n        class_value = ee.Number(ee.Feature(samples.sort('PRIM',False).first()).get('LANDCOVER')) #get LC numeric value for the given primitive (i.e. 'PRIM':1, 'LANDCOVER':6) then map to its class label (i.e. 6: 'Water')\n\n        # can experiment with classifier params for model performance\n        classifier = ee.Classifier.smileRandomForest(\n        numberOfTrees=100, \n        minLeafPopulation=1, \n        bagFraction=0.7, \n        seed=51515).setOutputMode('PROBABILITY')\n\n        # train model with all features\n        model = classifier.train(features=samples, \n                                classProperty='PRIM', \n                                inputProperties=inputs.bandNames() \n                                )\n\n        # store for model performance exploration\n        oob_all = ee.Dictionary(model.explain()).get('outOfBagErrorEstimate')\n        importance_all = ee.Dictionary(model.explain()).get('importance')\n\n        # retrieve top 20 most important features\n        top20 = gettop20(importance_all)\n\n        # re-train model with top20 important features\n        model = classifier.train(features=samples, \n                                classProperty='PRIM', \n                                inputProperties=top20\n                                )\n\n        oob_top20 = ee.Dictionary(model.explain()).get('outOfBagErrorEstimate')\n        importance_top20 = ee.Dictionary(model.explain()).get('importance')\n        schema = ee.List(ee.Classifier(model).schema())\n        output = (ee.Image(inputs)\n                  .classify(model,'Probability')\n                  # lists and dictionaries do not propagate thru as properties on Batch exported Images\n                  .set('Primitive',class_value,\n                       'importance',importance_top20, \n                       'schema',schema, \n                       'model',model,\n                       'oobError',oob_top20, \n                       ))\n        return output\n\n    def primitives_to_collection(input_stack,\n                                 training_pts,\n                                 class_name):\n        \"\"\"\n        Create LC Primitive image for each LC class in training points\n\n        args:\n            input_stack (ee.Image): of all covariates and predictor\n            training_pts (ee.FeatureCollection): training pts containing full LC typology\n            class_name (str): property name in training points containing model classes\n\n        returns:\n            ee.ImageCollection of Primitive ee.Images\n        \"\"\"\n\n        input_stack = ee.Image(input_stack)\n        training_pts = ee.FeatureCollection(training_pts)\n\n        # list of distinct LANDCOVER values\n        labels = training_pts.aggregate_array(class_name).distinct().sort().getInfo() # .sort() should fix Prims exporting out of order (i.e. 2,3,4,7,6)\n\n        # converting to index of the list of distinct LANDCOVER primtive FC's (prim_pts below)\n        indices = list(range(len(labels))) # handles dynamic land cover strata\n\n        prim_list = []\n        for i in indices: # running one LC class at a time\n            prim_pts = ee.FeatureCollection(ee.List(format_pts(training_pts)).get(i)) # format training pts to 1/0 prim format\n            img = RFprim(prim_pts,input_stack) # run RF primitive model, get output image and metrics\n            prim_list.append(img)\n\n        return ee.ImageCollection.fromImages(prim_list)\n\n    # you can construct Primitives object from a pre-existing Primitives ImgColl\n    if asset_id != None:\n        try:\n            primitives = ee.ImageCollection(asset_id)\n            self.collection = primitives\n            self.region = primitives.first().geometry().getInfo()\n            self.training_data = None\n        except: \n            raise(EEException)\n    else:\n        primitives = primitives_to_collection(inputs,training,class_name)\n        self.collection = primitives\n        self.region = ee.Image(inputs).geometry().getInfo()\n        self.training_data = ee.FeatureCollection(training)\n</code></pre>"},{"location":"primitives/#rlcms.primitives.Primitives.assemble_max_probability","title":"<code>assemble_max_probability()</code>","text":"<p>Take Image Collection of RF Primitives, perform pixel-wise maximum of all Primitive probability images to return single-band LC image Array computation returns img values from 0 to n-1 due to 0-base indexing, so we .add(1) to match LC strata</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <p>multiband image of probabilities</p> required <code>remapNum</code> <p>list, list of intergers 0-N matching the number of probability bands</p> required <code>originalNum</code> <p>list, list of inergers n-N matching the number of probability bands         that represent their desired map values</p> required <p>Returns: ee.Image of Land Cover</p> Source code in <code>src\\rlcms\\primitives.py</code> <pre><code>def assemble_max_probability(self):\n    \"\"\"\n    Take Image Collection of RF Primitives, perform pixel-wise maximum of all Primitive probability images to return single-band LC image\n    Array computation returns img values from 0 to n-1 due to 0-base indexing, so we .add(1) to match LC strata\n\n    Args:\n        image: multiband image of probabilities\n        remapNum: list, list of intergers 0-N matching the number of probability bands\n        originalNum: list, list of inergers n-N matching the number of probability bands\n                    that represent their desired map values\n\n    Returns: ee.Image of Land Cover                            \n    \"\"\"\n    def max_prob(image):\n\n        maxProbClassification = (image.toArray()\n                                .arrayArgmax()\n                                .arrayFlatten([['classification']])\n                                .rename('classification')\n                                )\n        return maxProbClassification\n\n    image  = self.collection.toBands()\n    max_probability = max_prob(image)\n    output = max_probability.add(1).rename('LANDCOVER')\n    return output\n</code></pre>"},{"location":"primitives/#rlcms.primitives.Primitives.export_metrics","title":"<code>export_metrics(metrics_path)</code>","text":"<p>Parse variable importance and OOB Error estimate from trained model, output to local files respectively Currently only works for Primitives objects in memory (not loaded from pre-existing ImgColl)</p> Source code in <code>src\\rlcms\\primitives.py</code> <pre><code>def export_metrics(self,metrics_path):\n        \"\"\"\n        Parse variable importance and OOB Error estimate from trained model, output to local files respectively\n        Currently only works for Primitives objects in memory (not loaded from pre-existing ImgColl)\n        \"\"\"\n        # Var Importance to csv file\n        imgColl = self.collection\n        to_list = ee.List(imgColl.toList(imgColl.size()))\n        for i in list(range(imgColl.size().getInfo())):\n            img = ee.Image(to_list.get(i))\n            prim_value = str(img.get('Primitive').getInfo())\n\n            # Variable Importance to .csv\n            dct = ee.Dictionary(img.get('importance')).getInfo()\n            _list = dct.values()\n            idx = dct.keys()\n            df = pd.DataFrame(_list, index = idx)\n            df.to_csv(os.path.join(metrics_path,f\"varImportancePrimitive{prim_value}.csv\"))\n\n            # OOB error to .txt file\n            oob = img.get('oobError')\n            with open(os.path.join(metrics_path,f'oobErrorPrimitive{prim_value}.txt'),mode='w') as f:\n                f.write(ee.String(ee.Number(oob).format()).getInfo())\n                f.close()\n</code></pre>"},{"location":"primitives/#rlcms.primitives.Primitives.export_to_asset","title":"<code>export_to_asset(collection_assetId=None, scale=None, crs=None, crsTransform=None, maxPixels=None, **kwargs)</code>","text":"<p>Export Primitives to Asset as an ImageCollection</p> <p>Parameters:</p> Name Type Description Default <code>collection_assetId</code> <code>str</code> <p>output ImageCollection asset path </p> <code>None</code> <code>scale</code> <code>int</code> <p>export scale</p> <code>None</code> <code>crs</code> <code>str</code> <p>export CRS ('EPSG:4326')</p> <code>None</code> <code>crsTransform</code> <code>list</code> <p>export CRS Transform</p> <code>None</code> <code>maxPixels</code> <code>int</code> <p>max Pixels</p> <code>None</code> <p>Returns:</p> Type Description <p>None, Submits all Export Image tasks for Primitive collection</p> Source code in <code>src\\rlcms\\primitives.py</code> <pre><code>def export_to_asset(self,\n                    collection_assetId=None,\n                    scale=None,\n                    crs=None,\n                    crsTransform=None,\n                    maxPixels=None,\n                    **kwargs):\n    \"\"\"\n    Export Primitives to Asset as an ImageCollection\n\n    Args:\n        collection_assetId (str): output ImageCollection asset path \n        scale (int): export scale\n        crs (str): export CRS ('EPSG:4326')\n        crsTransform (list): export CRS Transform\n        maxPixels (int): max Pixels\n\n    Returns: \n        None, Submits all Export Image tasks for Primitive collection\n    \"\"\"\n\n    # make the empty IC\n    print(f\"Creating empty Primitives ImageCollection: {collection_assetId}.\\n\")\n    os.popen(f\"earthengine create collection {collection_assetId}\").read()\n    prims_count = self.collection.size().getInfo()\n    prims_list = ee.ImageCollection(self.collection).toList(prims_count)\n    aoi = ee.Image(prims_list.get(0)).geometry()\n    for i in list(range(prims_count)):\n        prim = ee.Image(prims_list.get(i))\n        desc = f\"Primitive{str(ee.Image(prim).get('Primitive').getInfo())}\" # this would need to be defined in the Prims img for-loop\n        asset_id = f'{collection_assetId}/{desc}'\n        export_img_to_asset(image=prim,\n                            description=desc,\n                            assetId=asset_id,\n                            region=aoi,\n                            scale=scale,\n                            crs=crs,\n                            crsTransform=None,\n                            maxPixels=1e13)\n\n    return\n</code></pre>"},{"location":"primitives/#rlcms.primitives.Primitives.export_to_drive","title":"<code>export_to_drive(description, folder, fileNamePrefix, dimensions=None, region=None, scale=None, crs=None, crsTransform=None, maxPixels=None, shardSize=None, fileDimensions=None, skipEmptyTiles=None, fileFormat=None, formatOptions=None, **kwargs)</code>","text":"<p>Export Primitives to Drive as a Multi-band GeoTiff</p> <p>See rlcms.utils.export_img_to_drive() docs for Args</p> <p>Returns:</p> Type Description <p>None, Submits all Export Image tasks for Primitive collection</p> Source code in <code>src\\rlcms\\primitives.py</code> <pre><code>def export_to_drive(self,\n                    description,\n                    folder,\n                    fileNamePrefix,\n                    dimensions=None,\n                    region=None,\n                    scale=None,\n                    crs=None,\n                    crsTransform=None,\n                    maxPixels=None,\n                    shardSize=None,\n                    fileDimensions=None,\n                    skipEmptyTiles=None,\n                    fileFormat=None,\n                    formatOptions=None,\n                    **kwargs,):\n    \"\"\"\n    Export Primitives to Drive as a Multi-band GeoTiff\n\n    See rlcms.utils.export_img_to_drive() docs for Args\n\n    Returns: \n        None, Submits all Export Image tasks for Primitive collection\n    \"\"\"\n\n    prim_img = self.collection.toBands()\n    export_image_to_drive(image=prim_img,\n                            description=description,\n                            folder=folder,\n                            fileNamePrefix=fileNamePrefix,\n                            dimensions=dimensions,\n                            region=region,\n                            scale=scale,\n                            crs=crs,\n                            crsTransform=crsTransform,\n                            maxPixels=maxPixels,\n                            shardSize=shardSize,\n                            fileDimensions=fileDimensions,\n                            skipEmptyTiles=skipEmptyTiles,\n                            fileFormat=fileFormat,\n                            formatOptions=formatOptions,\n                            **kwargs,)\n    return\n</code></pre>"},{"location":"sampling/","title":"sampling module","text":""},{"location":"sampling/#rlcms.sampling.distanceFilter","title":"<code>distanceFilter(pts, distance)</code>","text":"<p>Filter Points within a FeatureCollection by a minimum distance threshold</p> Source code in <code>src\\rlcms\\sampling.py</code> <pre><code>def distanceFilter(pts,distance):\n    \"\"\"Filter Points within a FeatureCollection by a minimum distance threshold\"\"\"\n    withinDistance = distance\n\n    ## From the User Guide: https:#developers.google.com/earth-engine/joins_spatial\n    ## add extra filter to eliminate self-matches\n    distFilter = ee.Filter.And(ee.Filter.withinDistance(**{\n      'distance': withinDistance,\n      'leftField': '.geo',\n      'rightField': '.geo', \n      'maxError': 1\n    }), ee.Filter.notEquals(**{\n      'leftField': 'system:index',\n      'rightField': 'system:index',\n\n    }))\n\n    distSaveAll = ee.Join.saveAll(**{\n                  'matchesKey': 'points',\n                  'measureKey': 'distance'\n    })\n    # Apply the join.\n    spatialJoined = distSaveAll.apply(pts, pts, distFilter)\n\n    # Check the number of matches.\n    # We're only interested if nmatches &gt; 0.\n    spatialJoined = spatialJoined.map(lambda f: f.set('nmatches', ee.List(f.get('points')).size()) )\n    spatialJoined = spatialJoined.filterMetadata('nmatches', 'greater_than', 0)\n\n    # The real matches are only half the total, because if p1.withinDistance(p2) then p2.withinDistance(p1)\n    # Use some iterative logic to clean up\n    def unpack(l): \n        return ee.List(l).map(lambda f: ee.Feature(f).id())\n\n    def iterator_f(f,list):\n        key = ee.Feature(f).id()\n        list = ee.Algorithms.If(ee.List(list).contains(key), list, ee.List(list).cat(unpack(ee.List(f.get('points')))))\n        return list\n\n    ids = spatialJoined.iterate(iterator_f,ee.List([]))\n\n    # Clean up \n    cleaned_pts = pts.filter(ee.Filter.inList('system:index', ids).Not())\n    return cleaned_pts\n</code></pre>"},{"location":"sampling/#rlcms.sampling.plot_id_global","title":"<code>plot_id_global(n, feat)</code>","text":"<p>takes an index number (n) and adds it to current PLOTID property of a feature  to ensure PLOTID values are globally unique (necessary for multiple sets of AOI sampling)</p> Source code in <code>src\\rlcms\\sampling.py</code> <pre><code>def plot_id_global(n,feat):\n    \"\"\"takes an index number (n) and adds it to current PLOTID property of a feature \n            to ensure PLOTID values are globally unique (necessary for multiple sets of AOI sampling)\"\"\"\n    aoi_id = ee.String(str(n))\n    f = ee.Feature(feat)\n    gid = aoi_id.cat('_').cat(ee.String(f.get('PLOTID')))\n    f = f.set('PLOTID',gid, 'SAMPLEID', gid)\n    return f\n</code></pre>"},{"location":"sampling/#rlcms.sampling.split_train_test","title":"<code>split_train_test(pts, seed)</code>","text":"<p>stratify 80/20 train and test points</p> Source code in <code>src\\rlcms\\sampling.py</code> <pre><code>def split_train_test(pts,seed):\n    \"\"\"stratify 80/20 train and test points\"\"\"\n\n    featColl = ee.FeatureCollection(pts)\n    featColl = featColl.randomColumn(columnName='random', seed=seed)\n    filt = ee.Filter.lt('random',0.8)\n    train = featColl.filter(filt).map(lambda f: f.select(f.propertyNames().remove('random'))) # remove 'random' property\n    test = featColl.filter(filt.Not()).map(lambda f: f.select(f.propertyNames().remove('random')))\n\n    return train, test\n</code></pre>"},{"location":"sampling/#rlcms.sampling.strat_sample","title":"<code>strat_sample(img, class_band, region, scale, seed, n_points, class_values, class_points, ceo_format=True)</code>","text":"<p>A wrapper for ee.Image.stratifiedSample() with CEO schema formatting if desired Note: This function has been found to be less efficient on EECUs and Memory than those defined above.         Use the strat_sample_w_extraction for training data generation         strat_sample_no_extraction can be used for testing data generation (predictor bands not required)</p> Source code in <code>src\\rlcms\\sampling.py</code> <pre><code>def strat_sample(img,class_band,region,scale,seed,n_points,class_values,class_points,ceo_format=True):\n    \"\"\"\n    A wrapper for ee.Image.stratifiedSample() with CEO schema formatting if desired\n    Note: This function has been found to be less efficient on EECUs and Memory than those defined above.\n            Use the strat_sample_w_extraction for training data generation\n            strat_sample_no_extraction can be used for testing data generation (predictor bands not required)\n    \"\"\"\n    stratSample = ee.Image(img).stratifiedSample(\n        numPoints=n_points,\n        classBand=class_band,\n        region=region,\n        scale=scale, \n        seed=seed, \n        classValues=class_values,\n        classPoints=class_points,\n        dropNulls=True, \n        tileScale=16,\n        geometries=True)\n\n    if ceo_format:\n        return stratSample.map(ceoClean)\n    else:\n        return stratSample\n</code></pre>"},{"location":"sampling/#rlcms.sampling.strat_sample_from_reference","title":"<code>strat_sample_from_reference(img, collection, class_band, scale, crs, seed, class_values, class_points)</code>","text":"<p>Generates stratified random sample pts from reference polygons with all bands from input image extracted</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>Image</code> <p>image whose bands will be extracted to the sample points</p> required <code>collection</code> <code>FeatureCollection</code> <p>reference polygons FeatureCollection</p> required <code>class_band</code> <code>str</code> <p>property name of the reference (i.e. 'LANDCOVER')</p> required <code>scale</code> <code>int</code> <p>resolution to sample the grid at</p> required <code>seed</code> <code>int</code> <p>random seed</p> required <code>class_values</code> <code>list</code> <p>unique reference labels (e.g. [1,2,3,4])</p> required <code>class_points</code> <code>list</code> <p>number of points to sample per label (e.g. [100,200,100,200])</p> required <p>returns:   ee.FeatureCollection of sample points      They will contain the properties inherited from the reference polygons,        a 'random' property, and all bands from the image as properties.</p> Source code in <code>src\\rlcms\\sampling.py</code> <pre><code>def strat_sample_from_reference(img:ee.Image,collection:ee.FeatureCollection,class_band:str,scale:int,crs:str,seed:int,\n                              class_values:list,class_points:list):\n    \"\"\"\n    Generates stratified random sample pts from reference polygons with all bands from input image extracted\n\n    args:\n      img (ee.Image): image whose bands will be extracted to the sample points\n      collection (ee.FeatureCollection): reference polygons FeatureCollection\n      class_band (str): property name of the reference (i.e. 'LANDCOVER')\n      scale (int): resolution to sample the grid at\n      seed (int): random seed\n      class_values (list): unique reference labels (e.g. [1,2,3,4])\n      class_points (list): number of points to sample per label (e.g. [100,200,100,200])\n    returns:\n      ee.FeatureCollection of sample points \n        They will contain the properties inherited from the reference polygons, \n          a 'random' property, and all bands from the image as properties.\n    \"\"\"\n\n    # zip class_values and class_points together so they are easily accessible by map() index\n    zip_value_n = ee.List(class_values).zip(ee.List(class_points))\n\n    # done for each [class_value,class_points] pair\n    def do_by_class(value_n):\n        class_value = ee.List(value_n).get(0)\n        n_points = ee.List(value_n).get(1)\n        filtered_poly_by_class = collection.filter(ee.Filter.eq(class_band,class_value))\n\n        def fromPolys(coll):\n            geom = coll.geometry()\n            # generate n random pts, n_points*multiplier\n            multiplier = 2\n            random_pts = (ee.FeatureCollection.randomPoints(geom,ee.Number(n_points).multiply(multiplier),seed,0.001)\n                          .map(lambda f: f.set(class_band,class_value))) # class_band value from underlying poly geo must copy over into each point set\n            # extract raster data to the points then limit to n_points requested\n            rawSample_fromPts = ee.Image(img).sampleRegions(\n                collection=random_pts, \n                scale=scale,\n                projection=crs, \n                tileScale=16, \n                geometries=True).randomColumn().limit(n_points,'random')\n            return rawSample_fromPts\n        def fromPoints(coll):\n            # extract band info to every pt in coll, then limit to n_points requested\n            rawSample_fromPts = ee.Image(img).sampleRegions(\n                collection=coll, \n                scale=scale,\n                projection=crs, \n                tileScale=16, \n                geometries=True).randomColumn().limit(n_points,'random')\n            return rawSample_fromPts\n\n        # check if collection's geometry type is Polygon\n        types = ee.List([ee.String('Polygon'),ee.String('MultiPolygon')])\n        geom_type = collection.geometry().type()\n        # conditional: 1 if geom_type=='Polygon' or 'MultiPolygon', else 0 - this is a little hacky not sure if there's a better way\n        check_poly = types.map(lambda type: ee.String(type).match(geom_type)).flatten().size().gte(1)\n        samples = ee.Algorithms.If(check_poly,fromPolys(filtered_poly_by_class),fromPoints(filtered_poly_by_class))\n        # output_properties = ee.List(img.bandNames()).add(ee.String(class_band))\n\n        return ee.FeatureCollection(samples)#.map(lambda f: f.select(output_properties))\n\n    output_properties = ee.List(img.bandNames()).add(ee.String(class_band))\n    pts_by_class = ee.FeatureCollection(ee.List(zip_value_n).map(do_by_class)).flatten().map(lambda f: f.select(output_properties))\n    return pts_by_class\n</code></pre>"},{"location":"sampling/#rlcms.sampling.strat_sample_no_extraction","title":"<code>strat_sample_no_extraction(collection, class_band, scale, seed, class_values=None, class_points=None)</code>","text":"<p>Generates stratified random sample pts from reference polygons. Does not extract raster data to the points. </p> <p>Parameters:</p> Name Type Description Default <code>collection</code> <code>FeatureCollection</code> <p>reference polygons FeatureCollection</p> required <code>class_band</code> <code>str</code> <p>property name of the reference (i.e. 'LANDCOVER')</p> required <code>scale</code> <code>int</code> <p>resolution to sample the grid at</p> required <code>seed</code> <code>int</code> <p>random seed</p> required <code>class_values</code> <code>list</code> <p>unique reference labels (e.g. [1,2,3,4])</p> <code>None</code> <code>class_points</code> <code>list</code> <p>number of points to sample per label (e.g. [100,200,100,200])</p> <code>None</code> <p>returns:   ee.FeatureCollection of sample points      They will contain the properties inherited from the reference polygons and a 'random' property</p> Source code in <code>src\\rlcms\\sampling.py</code> <pre><code>def strat_sample_no_extraction(collection:ee.FeatureCollection,class_band:str,scale:int,seed:int,\n                               class_values:list=None,class_points:list=None):\n    \"\"\"\n    Generates stratified random sample pts from reference polygons. Does not extract raster data to the points. \n\n    args:\n      collection (ee.FeatureCollection): reference polygons FeatureCollection\n      class_band (str): property name of the reference (i.e. 'LANDCOVER')\n      scale (int): resolution to sample the grid at\n      seed (int): random seed\n      class_values (list): unique reference labels (e.g. [1,2,3,4])\n      class_points (list): number of points to sample per label (e.g. [100,200,100,200])\n    returns:\n      ee.FeatureCollection of sample points \n        They will contain the properties inherited from the reference polygons and a 'random' property\n    \"\"\"\n    # zip class_values and class_points together so they are easily accessible by map() index\n    zip_value_n = ee.List(class_values).zip(ee.List(class_points))\n\n    # done for each class and its desired n_points\n    def do_by_class(value_n):\n        class_value = ee.List(value_n).get(0)\n        n_points = ee.List(value_n).get(1)\n        # get polys by each class_band value at a time\n        filtered_poly_by_class = collection.filter(ee.Filter.eq(class_band,class_value))\n        geom = filtered_poly_by_class.geometry()\n        # generate random pts, more than user specified\n        random_pts = ee.FeatureCollection.randomPoints(geom,ee.Number(n_points).multiply(2),seed) \n        # filter out pts too close to each other at user specified scale\n        random_pts = (ee.FeatureCollection(distanceFilter(random_pts,scale))\n                      .randomColumn().limit(n_points,'random')) # shuffle, then try to return exact # pts user specified\n        # set class_band as a property to the features\n        random_pts = random_pts.map(lambda f: f.set(class_band,class_value))\n        return ee.FeatureCollection(random_pts)\n\n    pts_by_class = ee.FeatureCollection(ee.List(zip_value_n).map(do_by_class)).flatten()\n\n    return pts_by_class\n</code></pre>"},{"location":"sampling/#rlcms.sampling.strat_sample_w_extraction","title":"<code>strat_sample_w_extraction(img, collection, scale, crs, class_band, seed, class_values, class_points)</code>","text":"<p>Generates stratified random sample pts from reference polygons with all bands from input image extracted</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>Image</code> <p>image whose bands will be extracted to the sample points</p> required <code>collection</code> <code>FeatureCollection</code> <p>reference polygons FeatureCollection</p> required <code>class_band</code> <code>str</code> <p>property name of the reference (i.e. 'LANDCOVER')</p> required <code>scale</code> <code>int</code> <p>resolution to sample the grid at</p> required <code>seed</code> <code>int</code> <p>random seed</p> required <code>class_values</code> <code>list</code> <p>unique reference labels (e.g. [1,2,3,4])</p> required <code>class_points</code> <code>list</code> <p>number of points to sample per label (e.g. [100,200,100,200])</p> required <p>returns:   ee.FeatureCollection of sample points      They will contain the properties inherited from the reference polygons,        a 'random' property, and all bands from the image as properties.</p> Source code in <code>src\\rlcms\\sampling.py</code> <pre><code>def strat_sample_w_extraction(img:ee.Image,collection:ee.FeatureCollection,scale:int,crs:str,class_band:str,seed:int,\n                              class_values:list,class_points:list):\n  \"\"\"\n    Generates stratified random sample pts from reference polygons with all bands from input image extracted\n\n    args:\n      img (ee.Image): image whose bands will be extracted to the sample points\n      collection (ee.FeatureCollection): reference polygons FeatureCollection\n      class_band (str): property name of the reference (i.e. 'LANDCOVER')\n      scale (int): resolution to sample the grid at\n      seed (int): random seed\n      class_values (list): unique reference labels (e.g. [1,2,3,4])\n      class_points (list): number of points to sample per label (e.g. [100,200,100,200])\n    returns:\n      ee.FeatureCollection of sample points \n        They will contain the properties inherited from the reference polygons, \n          a 'random' property, and all bands from the image as properties.\n    \"\"\"\n\n  # zip class_values and class_points together so they are easily accessible by map() index\n  zip_value_n = ee.List(class_values).zip(ee.List(class_points))\n\n  # done for each [class_value,class_points] pair\n  def do_by_class(value_n):\n    class_value = ee.List(value_n).get(0)\n    n_points = ee.List(value_n).get(1)\n    filtered_poly_by_class = collection.filter(ee.Filter.eq(class_band,class_value))\n    geom = filtered_poly_by_class.geometry()\n    # generate random pts, more than user specified\n    random_pts = ee.FeatureCollection.randomPoints(geom,ee.Number(n_points).multiply(2),seed) \n    # set class_band as property \n    random_pts = random_pts.map(lambda f: f.set(class_band,class_value))\n    # extract raster data to the points and try to take specific n_points specified\n    rawSample_fromPts = ee.Image(img).sampleRegions(\n          collection=random_pts, \n          scale=scale,\n          projection=crs, \n          tileScale=16, \n          geometries=True).randomColumn().limit(n_points,'random')\n\n    return ee.FeatureCollection(rawSample_fromPts)\n\n\n  pts_by_class = ee.FeatureCollection(ee.List(zip_value_n).map(do_by_class)).flatten()\n  return pts_by_class\n</code></pre>"},{"location":"utils/","title":"utils module","text":""},{"location":"utils/#rlcms.utils.exportTableToAsset","title":"<code>exportTableToAsset(collection, description, asset_id)</code>","text":"<p>Export FeatureCollection to GEE Asset</p> Source code in <code>src\\rlcms\\utils.py</code> <pre><code>def exportTableToAsset(collection:ee.FeatureCollection,description:str,asset_id:str):\n    \"\"\"Export FeatureCollection to GEE Asset\"\"\"\n    if check_exists(asset_id) == 1:\n        task = ee.batch.Export.table.toAsset(\n            collection=collection,\n            description=description,\n            assetId=asset_id,\n            )\n        task.start()\n        print(f'Export started (Asset): {asset_id}')\n    else:\n        print(f\"{asset_id} already exists\")\n\n    return\n</code></pre>"},{"location":"utils/#rlcms.utils.exportTableToDrive","title":"<code>exportTableToDrive(collection, description, folder, file_name_prefix, selectors)</code>","text":"<p>export FeatureCollection to Google Drive</p> Source code in <code>src\\rlcms\\utils.py</code> <pre><code>def exportTableToDrive(collection:ee.FeatureCollection,description:str,folder:str,file_name_prefix:str,selectors:str):\n    \"\"\"export FeatureCollection to Google Drive\"\"\"\n    task = ee.batch.Export.table.toDrive(\n        collection=collection, \n        description=description, \n        folder=folder,\n        fileNamePrefix=file_name_prefix,\n        selectors=selectors)\n    task.start()\n    print(f'Export started (Drive): {folder}/{file_name_prefix}')\n    return\n</code></pre>"},{"location":"utils/#rlcms.utils.export_image_to_drive","title":"<code>export_image_to_drive(image, description='myExportImageTask', folder=None, fileNamePrefix=None, dimensions=None, region=None, scale=None, crs=None, crsTransform=None, maxPixels=None, shardSize=None, fileDimensions=None, skipEmptyTiles=None, fileFormat=None, formatOptions=None, **kwargs)</code>","text":"<p>Creates a batch task to export an Image as a raster to Google Drive.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <p>The image to be exported.</p> required <code>description</code> <p>Human-readable name of the task.</p> <code>'myExportImageTask'</code> <code>folder</code> <p>The name of a unique folder in your Drive account to export into. Defaults to the root of the drive.</p> <code>None</code> <code>fileNamePrefix</code> <p>The Google Drive filename for the export. Defaults to the name of the task.</p> <code>None</code> <code>dimensions</code> <p>The dimensions of the exported image. Takes either a single positive integer as the maximum dimension or \"WIDTHxHEIGHT\" where WIDTH and HEIGHT are each positive integers.</p> <code>None</code> <code>region</code> <p>The lon,lat coordinates for a LinearRing or Polygon specifying the region to export. Can be specified as a nested lists of numbers or a serialized string. Defaults to the image's region.</p> <code>None</code> <code>scale</code> <p>The resolution in meters per pixel. Defaults to the native resolution of the image assset unless a crsTransform is specified.</p> <code>None</code> <code>crs</code> <p>The coordinate reference system of the exported image's projection. Defaults to the image's default projection.</p> <code>None</code> <code>crsTransform</code> <p>A comma-separated string of 6 numbers describing the affine transform of the coordinate reference system of the exported image's projection, in the order: xScale, xShearing, xTranslation, yShearing, yScale and yTranslation. Defaults to the image's native CRS transform.</p> <code>None</code> <code>maxPixels</code> <p>The maximum allowed number of pixels in the exported image. The task will fail if the exported region covers more pixels in the specified projection. Defaults to 100,000,000.</p> <code>None</code> <code>shardSize</code> <p>Size in pixels of the tiles in which this image will be computed. Defaults to 256.</p> <code>None</code> <code>fileDimensions</code> <p>The dimensions in pixels of each image file, if the image is too large to fit in a single file. May specify a single number to indicate a square shape, or a tuple of two dimensions to indicate (width,height). Note that the image will still be clipped to the overall image dimensions. Must be a multiple of shardSize.</p> <code>None</code> <code>skipEmptyTiles</code> <p>If true, skip writing empty (i.e. fully-masked) image tiles. Defaults to false.</p> <code>None</code> <code>fileFormat</code> <p>The string file format to which the image is exported. Currently only 'GeoTIFF' and 'TFRecord' are supported, defaults to 'GeoTIFF'.</p> <code>None</code> <code>formatOptions</code> <p>A dictionary of string keys to format specific options.</p> <code>None</code> <code>**kwargs</code> <p>Holds other keyword arguments that may have been deprecated such as 'crs_transform', 'driveFolder', and 'driveFileNamePrefix'.</p> <code>{}</code> Source code in <code>src\\rlcms\\utils.py</code> <pre><code>def export_image_to_drive(\n    image,\n    description=\"myExportImageTask\",\n    folder=None,\n    fileNamePrefix=None,\n    dimensions=None,\n    region=None,\n    scale=None,\n    crs=None,\n    crsTransform=None,\n    maxPixels=None,\n    shardSize=None,\n    fileDimensions=None,\n    skipEmptyTiles=None,\n    fileFormat=None,\n    formatOptions=None,\n    **kwargs,\n):\n    \"\"\"Creates a batch task to export an Image as a raster to Google Drive.\n\n    Args:\n        image: The image to be exported.\n        description: Human-readable name of the task.\n        folder: The name of a unique folder in your Drive account to\n            export into. Defaults to the root of the drive.\n        fileNamePrefix: The Google Drive filename for the export.\n            Defaults to the name of the task.\n        dimensions: The dimensions of the exported image. Takes either a\n            single positive integer as the maximum dimension or \"WIDTHxHEIGHT\"\n            where WIDTH and HEIGHT are each positive integers.\n        region: The lon,lat coordinates for a LinearRing or Polygon\n            specifying the region to export. Can be specified as a nested\n            lists of numbers or a serialized string. Defaults to the image's\n            region.\n        scale: The resolution in meters per pixel. Defaults to the\n            native resolution of the image assset unless a crsTransform\n            is specified.\n        crs: The coordinate reference system of the exported image's\n            projection. Defaults to the image's default projection.\n        crsTransform: A comma-separated string of 6 numbers describing\n            the affine transform of the coordinate reference system of the\n            exported image's projection, in the order: xScale, xShearing,\n            xTranslation, yShearing, yScale and yTranslation. Defaults to\n            the image's native CRS transform.\n        maxPixels: The maximum allowed number of pixels in the exported\n            image. The task will fail if the exported region covers more\n            pixels in the specified projection. Defaults to 100,000,000.\n        shardSize: Size in pixels of the tiles in which this image will be\n            computed. Defaults to 256.\n        fileDimensions: The dimensions in pixels of each image file, if the\n            image is too large to fit in a single file. May specify a\n            single number to indicate a square shape, or a tuple of two\n            dimensions to indicate (width,height). Note that the image will\n            still be clipped to the overall image dimensions. Must be a\n            multiple of shardSize.\n        skipEmptyTiles: If true, skip writing empty (i.e. fully-masked)\n            image tiles. Defaults to false.\n        fileFormat: The string file format to which the image is exported.\n            Currently only 'GeoTIFF' and 'TFRecord' are supported, defaults to\n            'GeoTIFF'.\n        formatOptions: A dictionary of string keys to format specific options.\n        **kwargs: Holds other keyword arguments that may have been deprecated\n            such as 'crs_transform', 'driveFolder', and 'driveFileNamePrefix'.\n    \"\"\"\n\n    if not isinstance(image, ee.Image):\n        raise ValueError(\"Input image must be an instance of ee.Image\")\n\n    task = ee.batch.Export.image.toDrive(\n        image,\n        description,\n        folder,\n        fileNamePrefix,\n        dimensions,\n        region,\n        scale,\n        crs,\n        crsTransform,\n        maxPixels,\n        shardSize,\n        fileDimensions,\n        skipEmptyTiles,\n        fileFormat,\n        formatOptions,\n        **kwargs,\n    )\n    task.start()\n    print(f\"Export Started (Drive): {fileNamePrefix}\")\n</code></pre>"},{"location":"utils/#rlcms.utils.export_img_to_asset","title":"<code>export_img_to_asset(image, description='myExportImageTask', assetId=None, pyramidingPolicy=None, dimensions=None, region=None, scale=None, crs=None, crsTransform=None, maxPixels=None, **kwargs)</code>","text":"<p>Creates a task to export an EE Image to an EE Asset.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <p>The image to be exported.</p> required <code>description</code> <p>Human-readable name of the task.</p> <code>'myExportImageTask'</code> <code>assetId</code> <p>The destination asset ID.</p> <code>None</code> <code>pyramidingPolicy</code> <p>The pyramiding policy to apply to each band in the image, a dictionary keyed by band name. Values must be one of: \"mean\", \"sample\", \"min\", \"max\", or \"mode\". Defaults to \"mean\". A special key, \".default\", may be used to change the default for all bands.</p> <code>None</code> <code>dimensions</code> <p>The dimensions of the exported image. Takes either a single positive integer as the maximum dimension or \"WIDTHxHEIGHT\" where WIDTH and HEIGHT are each positive integers.</p> <code>None</code> <code>region</code> <p>The lon,lat coordinates for a LinearRing or Polygon specifying the region to export. Can be specified as a nested lists of numbers or a serialized string. Defaults to the image's region.</p> <code>None</code> <code>scale</code> <p>The resolution in meters per pixel. Defaults to the native resolution of the image assset unless a crsTransform is specified.</p> <code>None</code> <code>crs</code> <p>The coordinate reference system of the exported image's projection. Defaults to the image's default projection.</p> <code>None</code> <code>crsTransform</code> <p>A comma-separated string of 6 numbers describing the affine transform of the coordinate reference system of the exported image's projection, in the order: xScale, xShearing, xTranslation, yShearing, yScale and yTranslation. Defaults to the image's native CRS transform.</p> <code>None</code> <code>maxPixels</code> <p>The maximum allowed number of pixels in the exported image. The task will fail if the exported region covers more pixels in the specified projection. Defaults to 100,000,000.</p> <code>None</code> <code>**kwargs</code> <p>Holds other keyword arguments that may have been deprecated such as 'crs_transform'.</p> <code>{}</code> Source code in <code>src\\rlcms\\utils.py</code> <pre><code>def export_img_to_asset(image,\n    description=\"myExportImageTask\",\n    assetId=None,\n    pyramidingPolicy=None,\n    dimensions=None,\n    region=None,\n    scale=None,\n    crs=None,\n    crsTransform=None,\n    maxPixels=None,\n    **kwargs):\n    \"\"\"Creates a task to export an EE Image to an EE Asset.\n\n    Args:\n        image: The image to be exported.\n        description: Human-readable name of the task.\n        assetId: The destination asset ID.\n        pyramidingPolicy: The pyramiding policy to apply to each band in the\n            image, a dictionary keyed by band name. Values must be\n            one of: \"mean\", \"sample\", \"min\", \"max\", or \"mode\".\n            Defaults to \"mean\". A special key, \".default\", may be used to\n            change the default for all bands.\n        dimensions: The dimensions of the exported image. Takes either a\n            single positive integer as the maximum dimension or \"WIDTHxHEIGHT\"\n            where WIDTH and HEIGHT are each positive integers.\n        region: The lon,lat coordinates for a LinearRing or Polygon\n            specifying the region to export. Can be specified as a nested\n            lists of numbers or a serialized string. Defaults to the image's\n            region.\n        scale: The resolution in meters per pixel. Defaults to the\n            native resolution of the image assset unless a crsTransform\n            is specified.\n        crs: The coordinate reference system of the exported image's\n            projection. Defaults to the image's default projection.\n        crsTransform: A comma-separated string of 6 numbers describing\n            the affine transform of the coordinate reference system of the\n            exported image's projection, in the order: xScale, xShearing,\n            xTranslation, yShearing, yScale and yTranslation. Defaults to\n            the image's native CRS transform.\n        maxPixels: The maximum allowed number of pixels in the exported\n            image. The task will fail if the exported region covers more\n            pixels in the specified projection. Defaults to 100,000,000.\n        **kwargs: Holds other keyword arguments that may have been deprecated\n            such as 'crs_transform'.\n    \"\"\"\n\n    if isinstance(image, ee.Image) or isinstance(image, ee.image.Image):\n        pass\n    else:\n        raise ValueError(\"Input image must be an instance of ee.Image\")\n\n    if isinstance(assetId, str):\n        if assetId.startswith(\"users/\") or assetId.startswith(\"projects/\"):\n            pass\n        else:\n            assert check_exists(assetId) == 0, f\"{assetId} not a valid asset path\"\n            # assetId = f\"{ee_user_id()}/{assetId}\"\n\n    task = ee.batch.Export.image.toAsset(\n        image,\n        description,\n        assetId,\n        pyramidingPolicy,\n        dimensions,\n        region,\n        scale,\n        crs,\n        crsTransform,\n        maxPixels,\n        **kwargs,\n    )\n    task.start()\n    print(f\"Export Started (Asset): {assetId}\")\n</code></pre>"},{"location":"colab/compositing/","title":"Compositing Example","text":""},{"location":"colab/primitives/","title":"Primitives Example","text":""},{"location":"colab/sampling/","title":"Sampling Example","text":""}]}